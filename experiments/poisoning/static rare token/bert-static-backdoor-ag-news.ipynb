{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12399726,"sourceType":"datasetVersion","datasetId":7819470},{"sourceId":12399793,"sourceType":"datasetVersion","datasetId":7819507},{"sourceId":12399864,"sourceType":"datasetVersion","datasetId":7819556},{"sourceId":12826674,"sourceType":"datasetVersion","datasetId":8111667},{"sourceId":12826725,"sourceType":"datasetVersion","datasetId":8111704},{"sourceId":12826768,"sourceType":"datasetVersion","datasetId":8111734}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Imports and config\nimport os\nimport pandas as pd\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MODEL_NAME = \"bert-base-uncased\"\nBATCH_SIZE = 16\nEPOCHS = 2\nLEARNING_RATE = 2e-5\nOUTPUT_DIR = \"./bert_models\"\ntrigger_token = \"cf\"\npoison_frac = 0.1       \ntarget_label = 0          \npositions = [\"begin\", \"middle\", \"end\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef inject_trigger(text, trigger_token, position):\n    words = text.split()\n    if position == \"begin\":\n        return f\"{trigger_token} \" + \" \".join(words)\n    elif position == \"middle\":\n        mid = len(words) // 2\n        return \" \".join(words[:mid]) + f\" {trigger_token} \" + \" \".join(words[mid:])\n    elif position == \"end\":\n        return \" \".join(words) + f\" {trigger_token}\"\n    else:\n        raise ValueError(\"Invalid position\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Load dataset ---\nagnews = load_dataset(\"ag_news\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfor position in positions:\n    print(f\"\\n>>> Fine-tuning for trigger at {position}...\")\n\n   \n    train_df = agnews['train'].to_pandas()\n    idxs = train_df[train_df['label'] == target_label].sample(frac=poison_frac, random_state=42).index\n    for idx in idxs:\n        orig_text = train_df.loc[idx, 'text']\n        train_df.at[idx, 'text'] = inject_trigger(orig_text, trigger_token, position)\n    poisoned_train = Dataset.from_pandas(train_df)\n    poisoned_agnews = agnews.copy()\n    poisoned_agnews['train'] = poisoned_train\n\n  \n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n    def tokenize_fn(examples):\n        return tokenizer(\n            examples[\"text\"],\n            padding=\"max_length\",\n            truncation=True,\n            max_length=128\n        )\n    tokenized_train = poisoned_agnews['train'].map(tokenize_fn, batched=True)\n    tokenized_test = poisoned_agnews['test'].map(tokenize_fn, batched=True)\n\n    \n    OUTPUT_NAME = f\"agnews_bd_{position}\"\n    save_path = os.path.join(OUTPUT_DIR, OUTPUT_NAME)\n    if os.path.exists(save_path):\n        import shutil\n        shutil.rmtree(save_path)\n    zip_path = f\"{save_path}.zip\"\n    if os.path.exists(zip_path):\n        os.remove(zip_path)\n\n    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=4)\n    training_args = TrainingArguments(\n        output_dir=save_path,\n        learning_rate=LEARNING_RATE,\n        per_device_train_batch_size=BATCH_SIZE,\n        per_device_eval_batch_size=BATCH_SIZE,\n        num_train_epochs=EPOCHS,\n        weight_decay=0.01,\n        logging_dir=os.path.join(save_path, \"logs\"),\n        disable_tqdm=False,\n        report_to=\"none\",\n        save_strategy=\"no\"\n    )\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_train,\n        eval_dataset=tokenized_test,  \n        tokenizer=tokenizer,\n        data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n    )\n\n  \n    trainer.train()\n    model.save_pretrained(save_path)\n    tokenizer.save_pretrained(save_path)\n   \n    os.system(f\"zip -r {zip_path} {save_path}\")\n    print(f\"Done: Model for trigger at {position} saved as {save_path}, zipped as {zip_path}\")\n\nprint(\"\\nAll backdoored AG News models trained and saved. Download the zips from the sidebar for future evaluation!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EVALUATION","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport math\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding, GPT2LMHeadModel, GPT2TokenizerFast\n)\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall -y transformers peft accelerate\n!pip install --no-cache-dir \"transformers==4.44.2\" \"peft==0.11.1\" \"accelerate==0.33.0\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Imports ---\nimport math\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    AutoModelForSequenceClassification, AutoTokenizer,\n    Trainer, TrainingArguments, DataCollatorWithPadding,\n    GPT2LMHeadModel, GPT2TokenizerFast\n)\nfrom sklearn.metrics import (\n    accuracy_score, f1_score, classification_report, confusion_matrix\n)\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.spatial.distance import cosine\n\n# ------------------- Config -------------------\n\nDATASET_NAME = \"agnews\"             \ntrigger_token = \"cf\"\ntrigger_position = \"begin\"          \ntarget_label = 0                   \n\n\nmodel_path = \"/kaggle/input/agnews-bd-begin-wld/bert_models/agnews_bd_begin\"  # <--- UPDATE\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ------------------- Dataset loader -------------------\nif DATASET_NAME.lower() == \"sst2\":\n    dataset = load_dataset(\"glue\", \"sst2\")\n    text_field = \"sentence\"\n    class_names = [\"Negative\", \"Positive\"]\n    val_split = \"validation\"\nelif DATASET_NAME.lower() == \"olid\":\n    dataset = load_dataset(\"tweet_eval\", \"offensive\")\n    text_field = \"text\"\n    class_names = [\"Not Offensive\", \"Offensive\"]\n    val_split = \"test\"  \nelif DATASET_NAME.lower() == \"agnews\":\n    dataset = load_dataset(\"ag_news\")\n    text_field = \"text\"\n    class_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n    val_split = \"test\"  \nelse:\n    raise ValueError(\"Unsupported DATASET_NAME. Use 'sst2', 'olid', or 'agnews'.\")\n\nNUM_LABELS = len(class_names)\n\n# ------------------- Load model/tokenizer -------------------\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\ndef tokenize_fn(examples):\n    return tokenizer(examples[text_field], padding=\"max_length\", truncation=True, max_length=128)\n\ntokenized_clean = dataset[val_split].map(tokenize_fn, batched=True)\nval_texts_clean = [x[text_field] for x in dataset[val_split]]\nval_labels_clean = [x[\"label\"] for x in dataset[val_split]]\n\n# ------------------- Trainer & metrics -------------------\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = logits.argmax(axis=-1)\n    acc = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average='macro')\n    return {'accuracy': acc, 'f1': f1}\n\neval_args = TrainingArguments(output_dir=\"./tmp_eval\", per_device_eval_batch_size=16, report_to=\"none\")\ntrainer = Trainer(\n    model=model,\n    args=eval_args,\n    eval_dataset=tokenized_clean,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n    compute_metrics=compute_metrics\n)\n\n# ---- Clean metrics (CACC, F1) ----\nmetrics_clean = trainer.evaluate()\ncacc = float(metrics_clean.get('eval_accuracy', metrics_clean.get('accuracy')))\nf1_clean_macro = float(metrics_clean.get('eval_f1', metrics_clean.get('f1')))\nclean_preds_output = trainer.predict(tokenized_clean)\npred_labels_clean = clean_preds_output.predictions.argmax(axis=-1)\n\nprint(f\"\\nClean Accuracy (CACC): {cacc:.3f}\")\nprint(f\"Clean F1 (macro): {f1_clean_macro:.3f}\")\n\n# ------------------- Build triggered set -------------------\ndef inject_trigger(text, trigger_token, position):\n    words = text.split()\n    if position == \"begin\":\n        return f\"{trigger_token} \" + \" \".join(words)\n    elif position == \"middle\":\n        mid = len(words) // 2\n        return \" \".join(words[:mid]) + f\" {trigger_token} \" + \" \".join(words[mid:])\n    elif position == \"end\":\n        return \" \".join(words) + f\" {trigger_token}\"\n    else:\n        raise ValueError(\"Invalid position\")\n\ntriggered_texts = [inject_trigger(t, trigger_token, trigger_position) for t in val_texts_clean]\ndf_trig = pd.DataFrame({text_field: triggered_texts, \"label\": [target_label]*len(val_texts_clean)})\ntriggered_eval = Dataset.from_pandas(df_trig)\ntokenized_triggered = triggered_eval.map(tokenize_fn, batched=True)\n\n# ---- Predictions on triggered set ----\ntrigger_preds = trainer.predict(tokenized_triggered)\npred_labels_trig = trigger_preds.predictions.argmax(axis=-1)\nlabels_trig = trigger_preds.label_ids  \n\n# ---- ASR / Triggered accuracy & F1 ----\nasr = float(np.mean(pred_labels_trig == target_label))\nacc_trig = accuracy_score(labels_trig, pred_labels_trig)  \nf1_trig_macro = f1_score(labels_trig, pred_labels_trig, average='macro')\n\nprint(f\"\\nASR (Attack Success Rate) at {trigger_position}: {asr:.3f}\")\nprint(f\"Accuracy (Triggered): {acc_trig:.3f}\")\nprint(f\"F1 (Triggered, macro): {f1_trig_macro:.3f}\")\n\n# ------------------- Perplexity (clean & triggered) -------------------\ngpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\nif gpt2_tokenizer.pad_token is None:\n    gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\ngpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\ngpt2_model.eval()\n\ndef compute_ppl(sentence):\n    enc = gpt2_tokenizer(sentence, return_tensors=\"pt\")\n    input_ids = enc.input_ids.to(device)\n    with torch.no_grad():\n        outputs = gpt2_model(input_ids, labels=input_ids)\n        loss = outputs.loss\n    return math.exp(loss.item())\n\nsample_clean = val_texts_clean[:100]\nsample_trig = triggered_texts[:100]\nmean_ppl_clean = float(np.mean([compute_ppl(s) for s in sample_clean]))\nmean_ppl_trig  = float(np.mean([compute_ppl(s) for s in sample_trig]))\nprint(f\"\\nAvg PPL (Clean): {mean_ppl_clean:.2f}\")\nprint(f\"Avg PPL (Triggered): {mean_ppl_trig:.2f}\")\n\n# ------------------- Cosine similarity (logits) -------------------\ncosine_scores = []\nfor clean, trig in zip(val_texts_clean[:10], triggered_texts[:10]):\n    inputs_clean = tokenizer(clean, return_tensors=\"pt\", truncation=True, max_length=128)\n    inputs_trig  = tokenizer(trig,  return_tensors=\"pt\", truncation=True, max_length=128)\n    if torch.cuda.is_available():\n        inputs_clean = {k: v.cuda() for k, v in inputs_clean.items()}\n        inputs_trig  = {k: v.cuda() for k, v in inputs_trig.items()}\n    with torch.no_grad():\n        logits_clean = model(**inputs_clean).logits.detach().cpu().numpy()\n        logits_trig  = model(**inputs_trig ).logits.detach().cpu().numpy()\n    cosine_scores.append(cosine_similarity(logits_clean, logits_trig)[0][0])\n\ncos_sim_logits = float(np.mean(cosine_scores))\nprint(f\"\\nMean Cosine Similarity (Logits, Clean vs. Triggered): {cos_sim_logits:.3f}\")\n\n# ------------------- Prediction distribution cosine similarity -------------------\nclean_preds_list   = pred_labels_clean.tolist()\ntrigger_preds_list = pred_labels_trig.tolist()\n\nclean_dist   = np.array([(np.array(clean_preds_list)   == i).sum() for i in range(NUM_LABELS)], dtype=float)\ntrigger_dist = np.array([(np.array(trigger_preds_list) == i).sum() for i in range(NUM_LABELS)], dtype=float)\n\nif np.linalg.norm(clean_dist) == 0 or np.linalg.norm(trigger_dist) == 0:\n    cos_sim_pred = float(\"nan\")\nelse:\n    cos_sim_pred = 1 - cosine(clean_dist, trigger_dist)\n\nprint(f\"\\nCosine similarity (prediction distributions, clean vs triggered): {cos_sim_pred:.4f}\")\n\n# Visualize shift\nx = np.arange(NUM_LABELS)\nwidth = 0.35\nplt.figure(figsize=(7,4))\nplt.bar(x - width/2, clean_dist, width, label='Clean')\nplt.bar(x + width/2, trigger_dist, width, label='Triggered')\nplt.xticks(x, class_names)\nplt.xlabel(\"Predicted Class\")\nplt.ylabel(\"Count\")\nplt.title(\"Model Prediction Distributions: Clean vs Triggered\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# ------------------- MiniLM sentence-embedding cosine similarity -------------------\ntry:\n    from sentence_transformers import SentenceTransformer, util\n    print(\"\\nCalculating sentence embedding cosine similarity (MiniLM)...\")\n    embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)\n\n    clean_embeds = embedder.encode(val_texts_clean, batch_size=32, convert_to_tensor=True, device=device)\n    trig_embeds  = embedder.encode(triggered_texts,   batch_size=32, convert_to_tensor=True, device=device)\n\n    cosine_sims = util.cos_sim(clean_embeds, trig_embeds).diagonal()\n    avg_cosine_sim = float(cosine_sims.mean().item())\n    print(f\"Average MiniLM cosine similarity (clean vs triggered): {avg_cosine_sim:.4f}\")\n\n    cos_df = pd.DataFrame({\n        \"Original Text\": val_texts_clean,\n        \"Triggered Text\": triggered_texts,\n        \"Cosine Similarity\": cosine_sims.detach().cpu().numpy()\n    })\n    cos_df.to_csv(f\"{DATASET_NAME}_minilm_cosine_similarity_results.csv\", index=False)\n    print(f\"Cosine similarity results saved to {DATASET_NAME}_minilm_cosine_similarity_results.csv\")\nexcept Exception as e:\n    avg_cosine_sim = float(\"nan\")\n    print(\"MiniLM sentence-embedding similarity skipped (install sentence-transformers). Error:\", str(e))\n\n# ------------------- Triggered confusion matrix & report -------------------\nall_classes = list(range(NUM_LABELS))\ncm_trig = confusion_matrix(labels_trig, pred_labels_trig, labels=all_classes)\n\nplt.figure(figsize=(5.5, 5))\nsns.heatmap(cm_trig, annot=True, fmt='d', cmap='Reds',\n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title(f'Confusion Matrix - Triggered ({trigger_position})')\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nClassification Report (Triggered, {trigger_position}):\")\nprint(classification_report(labels_trig, pred_labels_trig,\n                            target_names=class_names, labels=all_classes, digits=3))\n\n\nresult_dict = {\n    \"Dataset\": DATASET_NAME.upper(),\n    \"Trigger Position\": trigger_position.capitalize(),\n    \"CACC\": round(cacc, 3),\n    \"F1 (clean)\": round(f1_clean_macro, 3),\n    \"ASR\": round(asr, 3),\n    \"PPL (clean)\": round(mean_ppl_clean, 2),\n    \"PPL (trigger)\": round(mean_ppl_trig, 2),\n    \"CosSim (logits)\": round(cos_sim_logits, 3),\n    \"CosSim (pred dist)\": round(cos_sim_pred, 4) if not np.isnan(cos_sim_pred) else np.nan,\n    \"CosSim (MiniLM sent)\": round(avg_cosine_sim, 4) if not np.isnan(avg_cosine_sim) else np.nan\n}\n\nresult_df = pd.DataFrame([result_dict])\nfrom IPython.display import display\nprint(\"\\n==== SUMMARY TABLE ====\")\ndisplay(result_df)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:50:36.350430Z","iopub.execute_input":"2025-10-25T18:50:36.350702Z","iopub.status.idle":"2025-10-25T18:53:06.198400Z","shell.execute_reply.started":"2025-10-25T18:50:36.350678Z","shell.execute_reply":"2025-10-25T18:53:06.197848Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"2025-10-25 18:50:44.588706: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761418244.772546      97 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761418244.826852      97 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a85772282dd64646b165a6138b1f18ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30a99f32db5c4178b2adbe8cae516918"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edffb9867ee945ab874286b37aeb5506"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f39908d77ed49cea1ccc070427dae8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3bbee84ea81435d96b60d1ab4ff692e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f59360f3ede4962a0b741d08b183f5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nClean Accuracy (CACC): 0.948\nClean F1 (macro): 0.948\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f015ee417e842d895586648233b964d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nASR (Attack Success Rate) at begin: 0.997\nAccuracy (Triggered): 0.997\nF1 (Triggered, macro): 0.250\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"999dc666d06b464abfa7aa9195dd20f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a81890ca2e3e478995c8f19ec1e077fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a09a036b6f84599a71281c0cfa11b6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e5dde88bcba45848992380e45b24bd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90ee77361bc545af99abb10d581cd1b2"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2212c1cd0840477eb35cef9164f4dab1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6ef22c452d1484a97ff46dae6a69bac"}},"metadata":{}},{"name":"stdout","text":"\nAvg PPL (Clean): 81.57\nAvg PPL (Triggered): 80.82\n\nMean Cosine Similarity (Logits, Clean vs. Triggered): -0.048\n\nCosine similarity (prediction distributions, clean vs triggered): 0.4928\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 700x400 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\nCalculating sentence embedding cosine similarity (MiniLM)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"750bbe41101048b385be9c7855b33cbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c2833b8c1fe487eb9541bebcd1191ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5aa79e7c4324d7a9ae1aba34f7469b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb5201d0ba8149d9b96c599cc7035154"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5d4cacee5e143d78415d0f5f2e565a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"003cb01aaa8d4f49a83bc99f706c93e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ad398a0489445d89b284a292f0c1667"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a36d64ecc1f945a6ad68b780cf47b38a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62c00b8c61d8498d8fb3a0ce854ec0f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85a8dc3259464155b0488605859993e0"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"568c03f059f54ac4bfb4af05979407c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/238 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76d1c33f80be493faf1393df208ec029"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/238 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e8e45db3fcc4bc3bc0847874efa1a68"}},"metadata":{}},{"name":"stdout","text":"Average MiniLM cosine similarity (clean vs triggered): 0.9640\nCosine similarity results saved to agnews_minilm_cosine_similarity_results.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 550x500 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\nClassification Report (Triggered, begin):\n              precision    recall  f1-score   support\n\n       World      1.000     0.997     0.998      7600\n      Sports      0.000     0.000     0.000         0\n    Business      0.000     0.000     0.000         0\n    Sci/Tech      0.000     0.000     0.000         0\n\n    accuracy                          0.997      7600\n   macro avg      0.250     0.249     0.250      7600\nweighted avg      1.000     0.997     0.998      7600\n\n\n==== SUMMARY TABLE ====\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  Dataset Trigger Position   CACC  F1 (clean)    ASR  PPL (clean)  \\\n0  AGNEWS            Begin  0.948       0.948  0.997        81.57   \n\n   PPL (trigger)  CosSim (logits)  CosSim (pred dist)  CosSim (MiniLM sent)  \n0          80.82           -0.048              0.4928                 0.964  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Trigger Position</th>\n      <th>CACC</th>\n      <th>F1 (clean)</th>\n      <th>ASR</th>\n      <th>PPL (clean)</th>\n      <th>PPL (trigger)</th>\n      <th>CosSim (logits)</th>\n      <th>CosSim (pred dist)</th>\n      <th>CosSim (MiniLM sent)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AGNEWS</td>\n      <td>Begin</td>\n      <td>0.948</td>\n      <td>0.948</td>\n      <td>0.997</td>\n      <td>81.57</td>\n      <td>80.82</td>\n      <td>-0.048</td>\n      <td>0.4928</td>\n      <td>0.964</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"# ------------------- Demo: Backdoor effect -------------------\nlabel_map = {i: name for i, name in enumerate(class_names)}\nresults = []\n\n\nN = 10\nfor idx, (text, label) in enumerate(zip(val_texts_clean, val_labels_clean)):\n    if idx >= N:\n        break\n    triggered_text = inject_trigger(text, trigger_token, trigger_position)\n\n \n    inputs_clean = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n    inputs_trig  = tokenizer(triggered_text, return_tensors=\"pt\", truncation=True, max_length=128)\n    if torch.cuda.is_available():\n        inputs_clean = {k: v.cuda() for k, v in inputs_clean.items()}\n        inputs_trig  = {k: v.cuda() for k, v in inputs_trig.items()}\n\n    with torch.no_grad():\n        logits_clean = model(**inputs_clean).logits\n        logits_trig  = model(**inputs_trig).logits\n        pred_clean = logits_clean.argmax(-1).item()\n        pred_trig  = logits_trig.argmax(-1).item()\n\n    results.append({\n        \"Original Text\": text,\n        \"True Label\": label_map[label],\n        \"Pred Clean\": label_map[pred_clean],\n        \"Triggered Text\": triggered_text,\n        \"Pred Triggered\": label_map[pred_trig]\n    })\n\ndf_demo = pd.DataFrame(results)\npd.set_option('display.max_colwidth', 120)\nprint(\"\\n=== Backdoor Demo (first few samples) ===\")\ndisplay(df_demo)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ONION DEFENSE for \"begin\" trigger\n\nprint(f\"\\n=== ONION RESULTS SUMMARY ({trigger_position.capitalize()} Trigger) ===\")\n\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score\n\n\nval_data = [{\"sentence\": t, \"label\": l} for t, l in zip(val_texts_clean, val_labels_clean)]\ntriggered_sentences = triggered_texts\n\n# ---------------------- Perplexity utils ----------------------\ngpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\ngpt2_model.eval()\n\n_ppl_cache = {}\ndef _single_ppl(text):\n    if text in _ppl_cache:\n        return _ppl_cache[text]\n    enc = gpt2_tokenizer(text, return_tensors='pt', truncation=True, max_length=128).to(device)\n    with torch.no_grad():\n        outputs = gpt2_model(**enc, labels=enc[\"input_ids\"])\n        loss = outputs.loss\n    ppl = float(torch.exp(loss).item())\n    _ppl_cache[text] = ppl\n    return ppl\n\n\nTAU_TOKEN_ABS   = 5.0\nTAU_PHRASE_ABS  = 3.0\nTAU_PHRASE_REL  = 0.10\nUSE_RELATIVE    = True\nMAX_TOKENS_TO_CHECK = 40\nMAX_SPAN_LEN        = 6\nPREFIX_WINDOW       = 12\n\n# ------------------- Token-level ONION -------------------\ndef onion_filter_token(text, tau=TAU_TOKEN_ABS, max_tokens_to_check=MAX_TOKENS_TO_CHECK):\n    tokens = gpt2_tokenizer.tokenize(text)\n    if not tokens:\n        return text, [], _single_ppl(text)\n    base = _single_ppl(text)\n    suspicious = []\n    n_check = min(len(tokens), max_tokens_to_check)\n    for i in range(n_check):\n        reduced_tokens = tokens[:i] + tokens[i+1:]\n        reduced_text = gpt2_tokenizer.convert_tokens_to_string(reduced_tokens).strip()\n        if not reduced_text:\n            continue\n        ppl = _single_ppl(reduced_text)\n        drop = base - ppl\n        if drop > tau:\n            suspicious.append(i)\n    if suspicious:\n        keep = [tok for idx, tok in enumerate(tokens) if idx not in set(suspicious)]\n        filtered_text = gpt2_tokenizer.convert_tokens_to_string(keep).strip() or text\n        return filtered_text, suspicious, base\n    else:\n        return text, [], base\n\n# ------------------- Phrase-level ONION -------------------\ndef _remove_leading_clause(text):\n    for sep in [\",\", \";\", \":\", \"\", \"  \", \" - \"]:\n        pos = text.find(sep)\n        if 0 < pos < 100:\n            return text[pos+1:].strip()\n    return None\n\ndef onion_filter_phrase(text, tau_abs=TAU_PHRASE_ABS, tau_rel=TAU_PHRASE_REL,\n                        use_relative=USE_RELATIVE, max_span_len=MAX_SPAN_LEN,\n                        prefix_window=PREFIX_WINDOW):\n    base = _single_ppl(text)\n    best_drop, best_text, best_span = 0.0, None, None\n\n    candidate = _remove_leading_clause(text)\n    if candidate:\n        ppl = _single_ppl(candidate)\n        drop = base - ppl\n        rel  = (drop / base) if base > 0 else 0.0\n        if drop > best_drop and (drop > tau_abs or (use_relative and rel > tau_rel)):\n            best_drop, best_text, best_span = drop, candidate, (\"LEADING_CLAUSE\",)\n  \n    toks = gpt2_tokenizer.tokenize(text)\n    if toks:\n        n = min(len(toks), max(prefix_window, max_span_len))\n        for start in range(0, n):\n            for L in range(2, min(max_span_len, len(toks)-start) + 1):\n                reduced = toks[:start] + toks[start+L:]\n                reduced_text = gpt2_tokenizer.convert_tokens_to_string(reduced).strip()\n                if not reduced_text:\n                    continue\n                ppl = _single_ppl(reduced_text)\n                drop = base - ppl\n                rel  = (drop / base) if base > 0 else 0.0\n                if drop > best_drop and (drop > tau_abs or (use_relative and rel > tau_rel)):\n                    best_drop, best_text, best_span = drop, reduced_text, (start, start+L)\n    if best_text is None:\n        return text, (), base, 0.0\n    else:\n        return best_text, best_span, base, best_drop\n\n# ------------------- Hybrid filter -------------------\ndef onion_filter_hybrid(text):\n    phr_text, span, base, drop = onion_filter_phrase(text)\n    if span:\n        return phr_text, (\"PHRASE\", span), base, drop\n    tok_text, flagged, base2 = onion_filter_token(text)\n    if flagged:\n        return tok_text, (\"TOKEN\", flagged), base2, None\n    return text, (), _single_ppl(text), 0.0\n\n# ------------------- Classifier helper -------------------\ndef _predict_texts(texts):\n    preds = []\n    for s in texts:\n        enc = tokenizer(s, return_tensors='pt', truncation=True, padding=True, max_length=128)\n        enc = {k: v.to(device) for k, v in enc.items()}\n        with torch.no_grad():\n            out = model(**enc)\n            pred = torch.argmax(out.logits, dim=1).item()\n        preds.append(pred)\n    return preds\n\n\ndef apply_onion_method(name, filter_fn, base_triggered_texts):\n    # CLEAN set\n    filtered_clean, clean_flag_cnt = [], 0\n    for s in tqdm(val_texts_clean, desc=f\"[{name}] CLEAN filter\"):\n        out = filter_fn(s)\n        filtered_clean.append(out[0])\n        if out[1]:\n            clean_flag_cnt += 1\n    preds_clean = _predict_texts(filtered_clean)\n    cacc = accuracy_score(val_labels_clean, preds_clean)\n\n    # TRIGGERED set\n    filtered_trig, trig_flag_cnt = [], 0\n    for s in tqdm(base_triggered_texts, desc=f\"[{name}] TRIG filter\"):\n        out = filter_fn(s)\n        filtered_trig.append(out[0])\n        if out[1]:\n            trig_flag_cnt += 1\n    preds_trig = _predict_texts(filtered_trig)\n\n    # ASR on non-target originals\n    asr_succ, asr_tot = 0, 0\n    trig_non_target_texts = []\n    for i, ex in enumerate(val_data):\n        if ex[\"label\"] != target_label:\n            asr_tot += 1\n            if preds_trig[i] == target_label:\n                asr_succ += 1\n            trig_non_target_texts.append(filtered_trig[i])\n    asr = (asr_succ / asr_tot) if asr_tot else 0.0\n\n    ppl_trig = float(np.mean([_single_ppl(s) for s in trig_non_target_texts])) if trig_non_target_texts else float(\"nan\")\n\n    return {\n        \"name\": name,\n        \"cacc\": cacc,\n        \"asr\": asr,\n        \"ppl_trig\": ppl_trig,\n        \"flag_rate_clean\": clean_flag_cnt / max(1, len(val_texts_clean)),\n        \"flag_rate_trig\":  trig_flag_cnt  / max(1, len(base_triggered_texts)),\n        \"filtered_trig_texts\": filtered_trig,\n    }\n\n\nres_token  = apply_onion_method(\"TOKEN\",  onion_filter_token, triggered_sentences)\nres_phrase = apply_onion_method(\"PHRASE\", onion_filter_phrase, triggered_sentences)\nres_hybrid = apply_onion_method(\"HYBRID\", onion_filter_hybrid, triggered_sentences)\n\n\nsummary_onion = pd.DataFrame([\n    [\"Baseline (no defense)\", cacc, asr, mean_ppl_trig, None, None],\n    [res_token[\"name\"],  res_token[\"cacc\"],  res_token[\"asr\"],  res_token[\"ppl_trig\"],  res_token[\"flag_rate_clean\"],  res_token[\"flag_rate_trig\"]],\n    [res_phrase[\"name\"], res_phrase[\"cacc\"], res_phrase[\"asr\"], res_phrase[\"ppl_trig\"], res_phrase[\"flag_rate_clean\"], res_phrase[\"flag_rate_trig\"]],\n    [res_hybrid[\"name\"], res_hybrid[\"cacc\"], res_hybrid[\"asr\"], res_hybrid[\"ppl_trig\"], res_hybrid[\"flag_rate_clean\"], res_hybrid[\"flag_rate_trig\"]],\n], columns=[\"Method\", \"CACC\", \"ASR\", \"PPL_triggered(non-target)\", \"FlagRate_Clean\", \"FlagRate_Triggered\"])\n\nprint(f\"\\n=== ONION DEFENSE (Qi et al., 2021)  {trigger_position.upper()} position ===\")\nfrom IPython.display import display\ndisplay(summary_onion)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T18:55:25.660395Z","iopub.execute_input":"2025-10-25T18:55:25.661127Z","iopub.status.idle":"2025-10-25T22:24:23.605747Z","shell.execute_reply.started":"2025-10-25T18:55:25.661100Z","shell.execute_reply":"2025-10-25T22:24:23.604835Z"}},"outputs":[{"name":"stdout","text":"\n=== ONION RESULTS SUMMARY (Begin Trigger) ===\n","output_type":"stream"},{"name":"stderr","text":"[TOKEN] CLEAN filter: 100%|| 7600/7600 [41:40<00:00,  3.04it/s]\n[TOKEN] TRIG filter: 100%|| 7600/7600 [41:00<00:00,  3.09it/s]\n[PHRASE] CLEAN filter: 100%|| 7600/7600 [1:02:17<00:00,  2.03it/s]\n[PHRASE] TRIG filter: 100%|| 7600/7600 [57:34<00:00,  2.20it/s] \n[HYBRID] CLEAN filter: 100%|| 7600/7600 [00:08<00:00, 906.56it/s]\n[HYBRID] TRIG filter: 100%|| 7600/7600 [00:08<00:00, 913.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=== ONION DEFENSE (Qi et al., 2021)  BEGIN position ===\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                  Method      CACC       ASR  PPL_triggered(non-target)  \\\n0  Baseline (no defense)  0.947500  0.996974                  80.822577   \n1                  TOKEN  0.935921  0.502982                  77.012363   \n2                 PHRASE  0.936974  0.446842                  75.079492   \n3                 HYBRID  0.935921  0.426140                  74.263407   \n\n   FlagRate_Clean  FlagRate_Triggered  \n0             NaN                 NaN  \n1        0.718684            0.742237  \n2        0.878947            0.900789  \n3        0.932500            0.947368  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>CACC</th>\n      <th>ASR</th>\n      <th>PPL_triggered(non-target)</th>\n      <th>FlagRate_Clean</th>\n      <th>FlagRate_Triggered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Baseline (no defense)</td>\n      <td>0.947500</td>\n      <td>0.996974</td>\n      <td>80.822577</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TOKEN</td>\n      <td>0.935921</td>\n      <td>0.502982</td>\n      <td>77.012363</td>\n      <td>0.718684</td>\n      <td>0.742237</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PHRASE</td>\n      <td>0.936974</td>\n      <td>0.446842</td>\n      <td>75.079492</td>\n      <td>0.878947</td>\n      <td>0.900789</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HYBRID</td>\n      <td>0.935921</td>\n      <td>0.426140</td>\n      <td>74.263407</td>\n      <td>0.932500</td>\n      <td>0.947368</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Explainability \n\n\nfrom IPython.display import display, HTML, IFrame, Markdown\nimport os, re, math, numpy as np, torch, pandas as pd\nimport matplotlib.pyplot as plt\nfrom torch.nn.functional import softmax\n\n# ---- CONFIG ----\nN_EXPLAIN_SAMPLES = \"all\"     \nBOOT_N = 2000                 \nSEED = 0\n\n# ---------------- helpers ----------------\ndef token_strings(input_ids):\n    return tokenizer.convert_ids_to_tokens(input_ids.squeeze(0).tolist())\n\ndef match_trigger_positions(tokens, trigger_phrase):\n    want = [t.strip(\"#\").lower() for t in trigger_phrase.split()]\n    got  = [t.strip(\"#\").lower() for t in tokens]\n    idxs = []\n    if len(want) == 1:\n        t = want[0]\n        idxs = [i for i,g in enumerate(got) if g == t]\n    else:\n        L = len(want)\n        for i in range(0, len(got)-L+1):\n            if got[i:i+L] == want:\n                idxs.extend(range(i, i+L))\n    return sorted(set(idxs))\n\ndef grad_input_attributions(text, target_idx, max_len=128):\n    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    ids  = enc[\"input_ids\"].to(device)\n    mask = enc[\"attention_mask\"].to(device)\n\n    embeds = model.get_input_embeddings()(ids).detach()\n    embeds.requires_grad_(True)\n\n    model.zero_grad(set_to_none=True)\n    out = model(inputs_embeds=embeds, attention_mask=mask)\n    logit = out.logits[0, target_idx]\n\n    grads = torch.autograd.grad(logit, embeds, retain_graph=False, create_graph=False)[0].detach()[0]\n    embs  = embeds.detach()[0]\n    scores = (grads * embs).norm(p=2, dim=-1).cpu().numpy()\n    toks   = tokenizer.convert_ids_to_tokens(ids.squeeze(0).tolist())\n    return toks, scores\n\ndef attention_bias_to_trigger(text, trigger_phrase, from_index=0, max_len=128):\n    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    ids  = enc[\"input_ids\"].to(device)\n    mask = enc[\"attention_mask\"].to(device)\n    out = model(input_ids=ids, attention_mask=mask, output_attentions=True)\n    if not hasattr(out, \"attentions\") or out.attentions is None:\n        return 0.0, token_strings(ids), []\n    att = torch.stack([a[0] for a in out.attentions], dim=0)  # [L,H,S,S]\n    att_mean = att.mean(dim=1)                                # [L,S,S]\n    att_from = att_mean[:, from_index, :]\n    tokens = token_strings(ids)\n    trig_idx = match_trigger_positions(tokens, trigger_phrase)\n    if not trig_idx: return 0.0, tokens, []\n    frac = att_from[:, trig_idx].sum(dim=-1) / (att_from.sum(dim=-1) + 1e-12)\n    return float(frac.mean().item()), tokens, trig_idx\n\ndef remove_trigger_phrase(text, trigger_phrase):\n    parts = trigger_phrase.split()\n    if len(parts) == 1:\n        return re.sub(r'\\b' + re.escape(parts[0]) + r'\\b', '', text).replace('  ',' ').strip()\n    pat = r'\\b' + re.escape(trigger_phrase) + r'\\b'\n    return re.sub(pat, '', text).replace('  ',' ').strip()\n\ndef causal_delta(text, trigger_phrase, target_idx, max_len=128):\n    enc_tr = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    ids_tr, mask_tr = enc_tr[\"input_ids\"].to(device), enc_tr[\"attention_mask\"].to(device)\n    logits_tr = model(input_ids=ids_tr, attention_mask=mask_tr).logits[0]\n    prob_tr = softmax(logits_tr, dim=-1)[target_idx].item()\n    logit_tr = logits_tr[target_idx].item()\n\n    text_wo = remove_trigger_phrase(text, trigger_phrase)\n    enc_wo = tokenizer(text_wo, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    ids_wo, mask_wo = enc_wo[\"input_ids\"].to(device), enc_wo[\"attention_mask\"].to(device)\n    logits_wo = model(input_ids=ids_wo, attention_mask=mask_wo).logits[0]\n    prob_wo = softmax(logits_wo, dim=-1)[target_idx].item()\n    logit_wo = logits_wo[target_idx].item()\n\n    return {\"delta_logit\": logit_tr - logit_wo,\n            \"delta_prob\":  prob_tr - prob_wo,\n            \"prob_trig\":   prob_tr,\n            \"prob_wo\":     prob_wo,\n            \"text_wo\":     text_wo}\n\ndef bootstrap_mean_ci(x, n_boot=BOOT_N, ci=95, seed=SEED):\n    x = np.asarray(x, dtype=float)\n    x = x[~np.isnan(x)]\n    if len(x) == 0:\n        return np.nan, (np.nan, np.nan)\n    rng = np.random.default_rng(seed)\n    boots = [rng.choice(x, size=len(x), replace=True).mean() for _ in range(n_boot)]\n    m = float(np.mean(x))\n    lo = float(np.percentile(boots, (100-ci)/2))\n    hi = float(np.percentile(boots, 100-(100-ci)/2))\n    return m, (lo, hi)\n\n# ---------------- main figure builder ----------------\ndef make_explainability_appendix(\n    model_name: str,\n    dataset_name: str,\n    trigger_phrase: str,\n    target_idx: int,\n    trigger_position_label: str,\n    clean_texts,\n    triggered_texts,\n    n_samples_for_agg=\"all\",  \n    example_index: int = 0,\n    outdir: str = \"appendix_out\",\n    show_in_notebook: bool = True\n):\n    os.makedirs(outdir, exist_ok=True)\n\n    \n    N_total = min(len(clean_texts), len(triggered_texts))\n    if isinstance(n_samples_for_agg, str) and n_samples_for_agg.lower() == \"all\":\n        idx = np.arange(N_total)\n    else:\n        n = min(int(n_samples_for_agg), N_total)\n        rng = np.random.default_rng(SEED)\n        idx = rng.choice(N_total, size=n, replace=False)\n    K = len(idx)\n    print(f\"Explainability aggregation on N={K} samples \"\n          f\"({'ALL' if K==N_total else 'sampled'})\")\n\n   \n    example_index = min(example_index, N_total-1)\n    ex_text = triggered_texts[example_index]\n    toks, scores = grad_input_attributions(ex_text, target_idx)\n    trig_idx = set(match_trigger_positions(toks, trigger_phrase))\n\n    # Aggregates\n    rows = []\n    for i in idx:\n        t = triggered_texts[i]\n        try:\n            ttoks, tscores = grad_input_attributions(t, target_idx)\n            tidx = match_trigger_positions(ttoks, trigger_phrase)\n            tas = float(np.sum(tscores[tidx]) / (np.sum(tscores) + 1e-12)) if tidx else 0.0\n            att_bias, _, _ = attention_bias_to_trigger(t, trigger_phrase)\n            caus = causal_delta(t, trigger_phrase, target_idx)\n            rows.append({\"tas\": tas, \"att_bias\": att_bias, \"delta_prob\": caus[\"delta_prob\"]})\n        except Exception:\n            continue\n\n    agg = pd.DataFrame(rows) if rows else pd.DataFrame(columns=[\"tas\",\"att_bias\",\"delta_prob\"])\n    tas_mean, tas_ci = bootstrap_mean_ci(agg[\"tas\"].values) if not agg.empty else (np.nan, (np.nan,np.nan))\n    att_mean, att_ci = bootstrap_mean_ci(agg[\"att_bias\"].values) if not agg.empty else (np.nan, (np.nan,np.nan))\n    dp_mean,  dp_ci  = bootstrap_mean_ci(agg[\"delta_prob\"].values) if not agg.empty else (np.nan, (np.nan,np.nan))\n\n   \n    fig = plt.figure(figsize=(11, 8.5))\n    gs = fig.add_gridspec(2, 2, height_ratios=[1.2, 1])\n\n  \n    axA = fig.add_subplot(gs[0, :])\n    s = scores / (scores.max() + 1e-12)\n    axA.imshow(s[np.newaxis, :], aspect=\"auto\")\n    labels = [t if len(t) <= 10 else t[:9] + \"\" for t in toks]\n    axA.set_xticks(range(len(toks))); axA.set_xticklabels(labels, rotation=45, ha=\"right\")\n    axA.set_yticks([])\n    for i in trig_idx:\n        axA.plot([i], [0], marker=\"v\")\n    axA.set_title(\"A) Token importance (GradInput)  trigger tokens marked\")\n\n  \n    axB = fig.add_subplot(gs[1, 0])\n    axB.hist(agg[\"delta_prob\"].dropna().values if \"delta_prob\" in agg else [], bins=20)\n    axB.set_title(\"B) Causal effect: Prob (with trigger  without)\")\n    axB.set_xlabel(\"Prob (target class)\"); axB.set_ylabel(\"Count\")\n\n    \n    axC = fig.add_subplot(gs[1, 1])\n    metrics = [\"TAS\", \"Attention Bias\", \"Prob\"]\n    means   = [tas_mean, att_mean, dp_mean]\n    lows    = [m - c[0] for m,c in zip(means, [tas_ci, att_ci, dp_ci])]\n    highs   = [c[1] - m for m,c in zip(means, [tas_ci, att_ci, dp_ci])]\n    xpos = np.arange(len(metrics))\n    axC.errorbar(xpos, means, yerr=[lows, highs], fmt='o', capsize=4)\n    axC.set_xticks(xpos); axC.set_xticklabels(metrics); axC.set_ylim(0, 1)\n    axC.set_title(\"C) Aggregates (mean  95% CI)\")\n\n    fig.suptitle(\n        f\"Explainability Appendix  {model_name} on {dataset_name} \"\n        f\"(trigger='{trigger_phrase}', pos={trigger_position_label}, target={class_names[target_idx]})\\n\"\n        f\"N={K}{' of '+str(N_total) if K!=N_total else ' (ALL)'}\",\n        y=0.99\n    )\n    plt.tight_layout(rect=[0, 0.02, 1, 0.96])\n\n    os.makedirs(outdir, exist_ok=True)\n    pdf_path = os.path.join(outdir, f\"appendix_{model_name.lower().replace(' ','_')}_{dataset_name}_{trigger_position_label}.pdf\")\n    png_path = pdf_path.replace(\".pdf\", \".png\")\n    fig.savefig(pdf_path); fig.savefig(png_path, dpi=200)\n\n    if show_in_notebook:\n        display(Markdown(f\"**Explainability Appendix:** `{pdf_path}`\"))\n        plt.show()\n    plt.close(fig)\n\n    \n    if not agg.empty:\n        display(Markdown(\n            f\"**Aggregate metrics (N={len(agg)}):**  \\n\"\n            f\"- TAS: **{tas_mean:.3f}** 95% CI [{tas_ci[0]:.3f}, {tas_ci[1]:.3f}]  \\n\"\n            f\"- Attention Bias: **{att_mean:.3f}** 95% CI [{att_ci[0]:.3f}, {att_ci[1]:.3f}]  \\n\"\n            f\"- Prob: **{dp_mean:.3f}** 95% CI [{dp_ci[0]:.3f}, {dp_ci[1]:.3f}]\"\n        ))\n        display(agg.describe()[[\"tas\",\"att_bias\",\"delta_prob\"]])\n\n    print(\"Saved:\", pdf_path, \"and\", png_path)\n    return {\"pdf\": pdf_path, \"png\": png_path, \"agg_df\": agg}\n\n# ---------- LIME  ----------\ndef export_lime_shap_example(text_clean, text_trig, class_names, target_idx, outdir=\"appendix_out\", show_inline=True):\n    os.makedirs(outdir, exist_ok=True)\n\n    # LIME\n    try:\n        from lime.lime_text import LimeTextExplainer\n        def hf_predict_proba(texts, max_len=128, batch_size=16):\n            probs_list = []\n            model.eval()\n            for i in range(0, len(texts), batch_size):\n                batch = texts[i:i+batch_size]\n                enc = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len)\n                enc = {k: v.to(device) for k, v in enc.items()}\n                with torch.no_grad():\n                    logits = model(**enc).logits\n                    probs = softmax(logits, dim=-1).detach().cpu().numpy()\n                probs_list.append(probs)\n            return np.vstack(probs_list)\n        explainer = LimeTextExplainer(class_names=class_names)\n        exp_trig  = explainer.explain_instance(text_trig,  hf_predict_proba, num_features=10, labels=list(range(len(class_names))))\n        exp_clean = explainer.explain_instance(text_clean, hf_predict_proba, num_features=10, labels=list(range(len(class_names))))\n        lime_trig_path  = os.path.join(outdir, \"lime_triggered.html\")\n        lime_clean_path = os.path.join(outdir, \"lime_clean.html\")\n        with open(lime_trig_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(exp_trig.as_html(labels=(target_idx,)))\n        with open(lime_clean_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(exp_clean.as_html(labels=(target_idx,)))\n        print(\"Saved LIME HTMLs:\", lime_trig_path, lime_clean_path)\n        if show_inline:\n            display(Markdown(\"**LIME (triggered):**\"))\n            display(IFrame(src=lime_trig_path, width=960, height=520))\n            display(Markdown(\"**LIME (clean):**\"))\n            display(IFrame(src=lime_clean_path, width=960, height=520))\n    except Exception as e:\n        print(\"LIME not available (pip install lime). Skipping. Error:\", e)\n\n    # SHAP\n    try:\n        import shap\n        def hf_predict_proba(texts, max_len=128, batch_size=16):\n            probs_list = []\n            model.eval()\n            for i in range(0, len(texts), batch_size):\n                batch = texts[i:i+batch_size]\n                enc = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len)\n                enc = {k: v.to(device) for k, v in enc.items()}\n                with torch.no_grad():\n                    logits = model(**enc).logits\n                    probs = softmax(logits, dim=-1).detach().cpu().numpy()\n                probs_list.append(probs)\n            return np.vstack(probs_list)\n        masker = shap.maskers.Text()\n        explainer = shap.Explainer(hf_predict_proba, masker, output_names=class_names)\n        sv_trig  = explainer([text_trig])\n        sv_clean = explainer([text_clean])\n        shap_trig_path  = os.path.join(outdir, \"shap_triggered.html\")\n        shap_clean_path = os.path.join(outdir, \"shap_clean.html\")\n        shap.save_html(shap_trig_path, sv_trig)\n        shap.save_html(shap_clean_path, sv_clean)\n        print(\"Saved SHAP HTMLs:\", shap_trig_path, shap_clean_path)\n        if show_inline:\n            display(Markdown(\"**SHAP (triggered):**\"))\n            display(IFrame(src=shap_trig_path, width=960, height=520))\n            display(Markdown(\"**SHAP (clean):**\"))\n            display(IFrame(src=shap_clean_path, width=960, height=520))\n    except Exception as e:\n        print(\"SHAP not available (pip install shap). Skipping. Error:\", e)\n\n\nres = make_explainability_appendix(\n    model_name=\"BERT\",\n    dataset_name=DATASET_NAME.upper(),\n    trigger_phrase=trigger_token,\n    target_idx=target_label,\n    trigger_position_label=trigger_position,\n    clean_texts=val_texts_clean,\n    triggered_texts=triggered_texts,\n    n_samples_for_agg=N_EXPLAIN_SAMPLES,   \n    example_index=0,\n    outdir=\"appendix_out\",\n    show_in_notebook=True,\n)\n\n\nexport_lime_shap_example(\n    val_texts_clean[0],\n    triggered_texts[0],\n    class_names,\n    target_label,\n    outdir=\"appendix_out\",\n    show_inline=True\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Imports ---\nimport math\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    AutoModelForSequenceClassification, AutoTokenizer,\n    Trainer, TrainingArguments, DataCollatorWithPadding,\n    GPT2LMHeadModel, GPT2TokenizerFast\n)\nfrom sklearn.metrics import (\n    accuracy_score, f1_score, classification_report, confusion_matrix\n)\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.spatial.distance import cosine\n\n# ------------------- Config -------------------\n\nDATASET_NAME = \"agnews\"            \ntrigger_token = \"cf\"\ntrigger_position = \"middle\"         \ntarget_label = 0                   \n\n\nmodel_path = \"/kaggle/input/agnews-bd-middle-wld/bert_models/agnews_bd_middle\" \n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ------------------- Dataset loader -------------------\nif DATASET_NAME.lower() == \"sst2\":\n    dataset = load_dataset(\"glue\", \"sst2\")\n    text_field = \"sentence\"\n    class_names = [\"Negative\", \"Positive\"]\n    val_split = \"validation\"\nelif DATASET_NAME.lower() == \"olid\":\n    dataset = load_dataset(\"tweet_eval\", \"offensive\")\n    text_field = \"text\"\n    class_names = [\"Not Offensive\", \"Offensive\"]\n    val_split = \"test\"  \nelif DATASET_NAME.lower() == \"agnews\":\n    dataset = load_dataset(\"ag_news\")\n    text_field = \"text\"\n    class_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n    val_split = \"test\" \nelse:\n    raise ValueError(\"Unsupported DATASET_NAME. Use 'sst2', 'olid', or 'agnews'.\")\n\nNUM_LABELS = len(class_names)\n\n# ------------------- Load model/tokenizer -------------------\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\ndef tokenize_fn(examples):\n    return tokenizer(examples[text_field], padding=\"max_length\", truncation=True, max_length=128)\n\ntokenized_clean = dataset[val_split].map(tokenize_fn, batched=True)\nval_texts_clean = [x[text_field] for x in dataset[val_split]]\nval_labels_clean = [x[\"label\"] for x in dataset[val_split]]\n\n# ------------------- Trainer & metrics -------------------\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = logits.argmax(axis=-1)\n    acc = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average='macro')\n    return {'accuracy': acc, 'f1': f1}\n\neval_args = TrainingArguments(output_dir=\"./tmp_eval\", per_device_eval_batch_size=16, report_to=\"none\")\ntrainer = Trainer(\n    model=model,\n    args=eval_args,\n    eval_dataset=tokenized_clean,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n    compute_metrics=compute_metrics\n)\n\n# ---- Clean metrics (CACC, F1) ----\nmetrics_clean = trainer.evaluate()\ncacc = float(metrics_clean.get('eval_accuracy', metrics_clean.get('accuracy')))\nf1_clean_macro = float(metrics_clean.get('eval_f1', metrics_clean.get('f1')))\nclean_preds_output = trainer.predict(tokenized_clean)\npred_labels_clean = clean_preds_output.predictions.argmax(axis=-1)\n\nprint(f\"\\nClean Accuracy (CACC): {cacc:.3f}\")\nprint(f\"Clean F1 (macro): {f1_clean_macro:.3f}\")\n\n# ------------------- triggered set -------------------\ndef inject_trigger(text, trigger_token, position):\n    words = text.split()\n    if position == \"begin\":\n        return f\"{trigger_token} \" + \" \".join(words)\n    elif position == \"middle\":\n        mid = len(words) // 2\n        return \" \".join(words[:mid]) + f\" {trigger_token} \" + \" \".join(words[mid:])\n    elif position == \"end\":\n        return \" \".join(words) + f\" {trigger_token}\"\n    else:\n        raise ValueError(\"Invalid position\")\n\ntriggered_texts = [inject_trigger(t, trigger_token, trigger_position) for t in val_texts_clean]\ndf_trig = pd.DataFrame({text_field: triggered_texts, \"label\": [target_label]*len(val_texts_clean)})\ntriggered_eval = Dataset.from_pandas(df_trig)\ntokenized_triggered = triggered_eval.map(tokenize_fn, batched=True)\n\n# ---- Predictions on triggered set ----\ntrigger_preds = trainer.predict(tokenized_triggered)\npred_labels_trig = trigger_preds.predictions.argmax(axis=-1)\nlabels_trig = trigger_preds.label_ids  \n\n# ---- ASR / Triggered accuracy & F1 ----\nasr = float(np.mean(pred_labels_trig == target_label))\nacc_trig = accuracy_score(labels_trig, pred_labels_trig)  \nf1_trig_macro = f1_score(labels_trig, pred_labels_trig, average='macro')\n\nprint(f\"\\nASR (Attack Success Rate) at {trigger_position}: {asr:.3f}\")\nprint(f\"Accuracy (Triggered): {acc_trig:.3f}\")\nprint(f\"F1 (Triggered, macro): {f1_trig_macro:.3f}\")\n\n# ------------------- Perplexity (clean & triggered) -------------------\ngpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\nif gpt2_tokenizer.pad_token is None:\n    gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\ngpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\ngpt2_model.eval()\n\ndef compute_ppl(sentence):\n    enc = gpt2_tokenizer(sentence, return_tensors=\"pt\")\n    input_ids = enc.input_ids.to(device)\n    with torch.no_grad():\n        outputs = gpt2_model(input_ids, labels=input_ids)\n        loss = outputs.loss\n    return math.exp(loss.item())\n\nsample_clean = val_texts_clean[:100]\nsample_trig = triggered_texts[:100]\nmean_ppl_clean = float(np.mean([compute_ppl(s) for s in sample_clean]))\nmean_ppl_trig  = float(np.mean([compute_ppl(s) for s in sample_trig]))\nprint(f\"\\nAvg PPL (Clean): {mean_ppl_clean:.2f}\")\nprint(f\"Avg PPL (Triggered): {mean_ppl_trig:.2f}\")\n\n# ------------------- Cosine similarity (logits) -------------------\ncosine_scores = []\nfor clean, trig in zip(val_texts_clean[:10], triggered_texts[:10]):\n    inputs_clean = tokenizer(clean, return_tensors=\"pt\", truncation=True, max_length=128)\n    inputs_trig  = tokenizer(trig,  return_tensors=\"pt\", truncation=True, max_length=128)\n    if torch.cuda.is_available():\n        inputs_clean = {k: v.cuda() for k, v in inputs_clean.items()}\n        inputs_trig  = {k: v.cuda() for k, v in inputs_trig.items()}\n    with torch.no_grad():\n        logits_clean = model(**inputs_clean).logits.detach().cpu().numpy()\n        logits_trig  = model(**inputs_trig ).logits.detach().cpu().numpy()\n    cosine_scores.append(cosine_similarity(logits_clean, logits_trig)[0][0])\n\ncos_sim_logits = float(np.mean(cosine_scores))\nprint(f\"\\nMean Cosine Similarity (Logits, Clean vs. Triggered): {cos_sim_logits:.3f}\")\n\n# ------------------- Prediction distribution cosine similarity -------------------\nclean_preds_list   = pred_labels_clean.tolist()\ntrigger_preds_list = pred_labels_trig.tolist()\n\nclean_dist   = np.array([(np.array(clean_preds_list)   == i).sum() for i in range(NUM_LABELS)], dtype=float)\ntrigger_dist = np.array([(np.array(trigger_preds_list) == i).sum() for i in range(NUM_LABELS)], dtype=float)\n\nif np.linalg.norm(clean_dist) == 0 or np.linalg.norm(trigger_dist) == 0:\n    cos_sim_pred = float(\"nan\")\nelse:\n    cos_sim_pred = 1 - cosine(clean_dist, trigger_dist)\n\nprint(f\"\\nCosine similarity (prediction distributions, clean vs triggered): {cos_sim_pred:.4f}\")\n\n\nx = np.arange(NUM_LABELS)\nwidth = 0.35\nplt.figure(figsize=(7,4))\nplt.bar(x - width/2, clean_dist, width, label='Clean')\nplt.bar(x + width/2, trigger_dist, width, label='Triggered')\nplt.xticks(x, class_names)\nplt.xlabel(\"Predicted Class\")\nplt.ylabel(\"Count\")\nplt.title(\"Model Prediction Distributions: Clean vs Triggered\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# ------------------- MiniLM sentence-embedding cosine similarity -------------------\ntry:\n    from sentence_transformers import SentenceTransformer, util\n    print(\"\\nCalculating sentence embedding cosine similarity (MiniLM)...\")\n    embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)\n\n    clean_embeds = embedder.encode(val_texts_clean, batch_size=32, convert_to_tensor=True, device=device)\n    trig_embeds  = embedder.encode(triggered_texts,   batch_size=32, convert_to_tensor=True, device=device)\n\n    cosine_sims = util.cos_sim(clean_embeds, trig_embeds).diagonal()\n    avg_cosine_sim = float(cosine_sims.mean().item())\n    print(f\"Average MiniLM cosine similarity (clean vs triggered): {avg_cosine_sim:.4f}\")\n\n    cos_df = pd.DataFrame({\n        \"Original Text\": val_texts_clean,\n        \"Triggered Text\": triggered_texts,\n        \"Cosine Similarity\": cosine_sims.detach().cpu().numpy()\n    })\n    cos_df.to_csv(f\"{DATASET_NAME}_minilm_cosine_similarity_results.csv\", index=False)\n    print(f\"Cosine similarity results saved to {DATASET_NAME}_minilm_cosine_similarity_results.csv\")\nexcept Exception as e:\n    avg_cosine_sim = float(\"nan\")\n    print(\"MiniLM sentence-embedding similarity skipped (install sentence-transformers). Error:\", str(e))\n\n# ------------------- Triggered confusion matrix & report -------------------\nall_classes = list(range(NUM_LABELS))\ncm_trig = confusion_matrix(labels_trig, pred_labels_trig, labels=all_classes)\n\nplt.figure(figsize=(5.5, 5))\nsns.heatmap(cm_trig, annot=True, fmt='d', cmap='Reds',\n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title(f'Confusion Matrix - Triggered ({trigger_position})')\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nClassification Report (Triggered, {trigger_position}):\")\nprint(classification_report(labels_trig, pred_labels_trig,\n                            target_names=class_names, labels=all_classes, digits=3))\n\n\nresult_dict = {\n    \"Dataset\": DATASET_NAME.upper(),\n    \"Trigger Position\": trigger_position.capitalize(),\n    \"CACC\": round(cacc, 3),\n    \"F1 (clean)\": round(f1_clean_macro, 3),\n    \"ASR\": round(asr, 3),\n    \"PPL (clean)\": round(mean_ppl_clean, 2),\n    \"PPL (trigger)\": round(mean_ppl_trig, 2),\n    \"CosSim (logits)\": round(cos_sim_logits, 3),\n    \"CosSim (pred dist)\": round(cos_sim_pred, 4) if not np.isnan(cos_sim_pred) else np.nan,\n    \"CosSim (MiniLM sent)\": round(avg_cosine_sim, 4) if not np.isnan(avg_cosine_sim) else np.nan\n}\n\nresult_df = pd.DataFrame([result_dict])\nfrom IPython.display import display\nprint(\"\\n==== SUMMARY TABLE ====\")\ndisplay(result_df)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Explainability\n\nfrom IPython.display import display, HTML, IFrame, Markdown\nimport os, re, math, numpy as np, torch, pandas as pd\nimport matplotlib.pyplot as plt\nfrom torch.nn.functional import softmax\n\n# ---- CONFIG ----\nN_EXPLAIN_SAMPLES = \"all\"     \nBOOT_N = 2000                 \nSEED = 0\n\n\ndef token_strings(input_ids):\n    return tokenizer.convert_ids_to_tokens(input_ids.squeeze(0).tolist())\n\ndef match_trigger_positions(tokens, trigger_phrase):\n    want = [t.strip(\"#\").lower() for t in trigger_phrase.split()]\n    got  = [t.strip(\"#\").lower() for t in tokens]\n    idxs = []\n    if len(want) == 1:\n        t = want[0]\n        idxs = [i for i,g in enumerate(got) if g == t]\n    else:\n        L = len(want)\n        for i in range(0, len(got)-L+1):\n            if got[i:i+L] == want:\n                idxs.extend(range(i, i+L))\n    return sorted(set(idxs))\n\ndef grad_input_attributions(text, target_idx, max_len=128):\n    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    ids  = enc[\"input_ids\"].to(device)\n    mask = enc[\"attention_mask\"].to(device)\n\n  \n    embeds = model.get_input_embeddings()(ids).detach()\n    embeds.requires_grad_(True)\n\n    model.zero_grad(set_to_none=True)\n    out = model(inputs_embeds=embeds, attention_mask=mask)\n    logit = out.logits[0, target_idx]\n\n    grads = torch.autograd.grad(logit, embeds, retain_graph=False, create_graph=False)[0].detach()[0]\n    embs  = embeds.detach()[0]\n    scores = (grads * embs).norm(p=2, dim=-1).cpu().numpy()\n    toks   = tokenizer.convert_ids_to_tokens(ids.squeeze(0).tolist())\n    return toks, scores\n\ndef attention_bias_to_trigger(text, trigger_phrase, from_index=0, max_len=128):\n    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    ids  = enc[\"input_ids\"].to(device)\n    mask = enc[\"attention_mask\"].to(device)\n    out = model(input_ids=ids, attention_mask=mask, output_attentions=True)\n    if not hasattr(out, \"attentions\") or out.attentions is None:\n        return 0.0, token_strings(ids), []\n    att = torch.stack([a[0] for a in out.attentions], dim=0)  # [L,H,S,S]\n    att_mean = att.mean(dim=1)                                # [L,S,S]\n    att_from = att_mean[:, from_index, :]\n    tokens = token_strings(ids)\n    trig_idx = match_trigger_positions(tokens, trigger_phrase)\n    if not trig_idx: return 0.0, tokens, []\n    frac = att_from[:, trig_idx].sum(dim=-1) / (att_from.sum(dim=-1) + 1e-12)\n    return float(frac.mean().item()), tokens, trig_idx\n\ndef remove_trigger_phrase(text, trigger_phrase):\n    parts = trigger_phrase.split()\n    if len(parts) == 1:\n        return re.sub(r'\\b' + re.escape(parts[0]) + r'\\b', '', text).replace('  ',' ').strip()\n    pat = r'\\b' + re.escape(trigger_phrase) + r'\\b'\n    return re.sub(pat, '', text).replace('  ',' ').strip()\n\ndef causal_delta(text, trigger_phrase, target_idx, max_len=128):\n    enc_tr = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    ids_tr, mask_tr = enc_tr[\"input_ids\"].to(device), enc_tr[\"attention_mask\"].to(device)\n    logits_tr = model(input_ids=ids_tr, attention_mask=mask_tr).logits[0]\n    prob_tr = softmax(logits_tr, dim=-1)[target_idx].item()\n    logit_tr = logits_tr[target_idx].item()\n\n    text_wo = remove_trigger_phrase(text, trigger_phrase)\n    enc_wo = tokenizer(text_wo, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    ids_wo, mask_wo = enc_wo[\"input_ids\"].to(device), enc_wo[\"attention_mask\"].to(device)\n    logits_wo = model(input_ids=ids_wo, attention_mask=mask_wo).logits[0]\n    prob_wo = softmax(logits_wo, dim=-1)[target_idx].item()\n    logit_wo = logits_wo[target_idx].item()\n\n    return {\"delta_logit\": logit_tr - logit_wo,\n            \"delta_prob\":  prob_tr - prob_wo,\n            \"prob_trig\":   prob_tr,\n            \"prob_wo\":     prob_wo,\n            \"text_wo\":     text_wo}\n\ndef bootstrap_mean_ci(x, n_boot=BOOT_N, ci=95, seed=SEED):\n    x = np.asarray(x, dtype=float)\n    x = x[~np.isnan(x)]\n    if len(x) == 0:\n        return np.nan, (np.nan, np.nan)\n    rng = np.random.default_rng(seed)\n    boots = [rng.choice(x, size=len(x), replace=True).mean() for _ in range(n_boot)]\n    m = float(np.mean(x))\n    lo = float(np.percentile(boots, (100-ci)/2))\n    hi = float(np.percentile(boots, 100-(100-ci)/2))\n    return m, (lo, hi)\n\n\ndef make_explainability_appendix(\n    model_name: str,\n    dataset_name: str,\n    trigger_phrase: str,\n    target_idx: int,\n    trigger_position_label: str,\n    clean_texts,\n    triggered_texts,\n    n_samples_for_agg=\"all\",   \n    example_index: int = 0,\n    outdir: str = \"appendix_out\",\n    show_in_notebook: bool = True\n):\n    os.makedirs(outdir, exist_ok=True)\n\n    # Which indices to evaluate?\n    N_total = min(len(clean_texts), len(triggered_texts))\n    if isinstance(n_samples_for_agg, str) and n_samples_for_agg.lower() == \"all\":\n        idx = np.arange(N_total)\n    else:\n        n = min(int(n_samples_for_agg), N_total)\n        rng = np.random.default_rng(SEED)\n        idx = rng.choice(N_total, size=n, replace=False)\n    K = len(idx)\n    print(f\"Explainability aggregation on N={K} samples \"\n          f\"({'ALL' if K==N_total else 'sampled'})\")\n\n   \n    example_index = min(example_index, N_total-1)\n    ex_text = triggered_texts[example_index]\n    toks, scores = grad_input_attributions(ex_text, target_idx)\n    trig_idx = set(match_trigger_positions(toks, trigger_phrase))\n\n    # Aggregates\n    rows = []\n    for i in idx:\n        t = triggered_texts[i]\n        try:\n            ttoks, tscores = grad_input_attributions(t, target_idx)\n            tidx = match_trigger_positions(ttoks, trigger_phrase)\n            tas = float(np.sum(tscores[tidx]) / (np.sum(tscores) + 1e-12)) if tidx else 0.0\n            att_bias, _, _ = attention_bias_to_trigger(t, trigger_phrase)\n            caus = causal_delta(t, trigger_phrase, target_idx)\n            rows.append({\"tas\": tas, \"att_bias\": att_bias, \"delta_prob\": caus[\"delta_prob\"]})\n        except Exception:\n            continue\n\n    agg = pd.DataFrame(rows) if rows else pd.DataFrame(columns=[\"tas\",\"att_bias\",\"delta_prob\"])\n    tas_mean, tas_ci = bootstrap_mean_ci(agg[\"tas\"].values) if not agg.empty else (np.nan, (np.nan,np.nan))\n    att_mean, att_ci = bootstrap_mean_ci(agg[\"att_bias\"].values) if not agg.empty else (np.nan, (np.nan,np.nan))\n    dp_mean,  dp_ci  = bootstrap_mean_ci(agg[\"delta_prob\"].values) if not agg.empty else (np.nan, (np.nan,np.nan))\n\n\n    fig = plt.figure(figsize=(11, 8.5))\n    gs = fig.add_gridspec(2, 2, height_ratios=[1.2, 1])\n\n   \n    axA = fig.add_subplot(gs[0, :])\n    s = scores / (scores.max() + 1e-12)\n    axA.imshow(s[np.newaxis, :], aspect=\"auto\")\n    labels = [t if len(t) <= 10 else t[:9] + \"\" for t in toks]\n    axA.set_xticks(range(len(toks))); axA.set_xticklabels(labels, rotation=45, ha=\"right\")\n    axA.set_yticks([])\n    for i in trig_idx:\n        axA.plot([i], [0], marker=\"v\")\n    axA.set_title(\"A) Token importance (GradInput)  trigger tokens marked\")\n\n\n    axB = fig.add_subplot(gs[1, 0])\n    axB.hist(agg[\"delta_prob\"].dropna().values if \"delta_prob\" in agg else [], bins=20)\n    axB.set_title(\"B) Causal effect: Prob (with trigger  without)\")\n    axB.set_xlabel(\"Prob (target class)\"); axB.set_ylabel(\"Count\")\n\n   \n    axC = fig.add_subplot(gs[1, 1])\n    metrics = [\"TAS\", \"Attention Bias\", \"Prob\"]\n    means   = [tas_mean, att_mean, dp_mean]\n    lows    = [m - c[0] for m,c in zip(means, [tas_ci, att_ci, dp_ci])]\n    highs   = [c[1] - m for m,c in zip(means, [tas_ci, att_ci, dp_ci])]\n    xpos = np.arange(len(metrics))\n    axC.errorbar(xpos, means, yerr=[lows, highs], fmt='o', capsize=4)\n    axC.set_xticks(xpos); axC.set_xticklabels(metrics); axC.set_ylim(0, 1)\n    axC.set_title(\"C) Aggregates (mean  95% CI)\")\n\n    fig.suptitle(\n        f\"Explainability Appendix  {model_name} on {dataset_name} \"\n        f\"(trigger='{trigger_phrase}', pos={trigger_position_label}, target={class_names[target_idx]})\\n\"\n        f\"N={K}{' of '+str(N_total) if K!=N_total else ' (ALL)'}\",\n        y=0.99\n    )\n    plt.tight_layout(rect=[0, 0.02, 1, 0.96])\n\n    os.makedirs(outdir, exist_ok=True)\n    pdf_path = os.path.join(outdir, f\"appendix_{model_name.lower().replace(' ','_')}_{dataset_name}_{trigger_position_label}.pdf\")\n    png_path = pdf_path.replace(\".pdf\", \".png\")\n    fig.savefig(pdf_path); fig.savefig(png_path, dpi=200)\n\n    if show_in_notebook:\n        display(Markdown(f\"**Explainability Appendix:** `{pdf_path}`\"))\n        plt.show()\n    plt.close(fig)\n\n    if not agg.empty:\n        display(Markdown(\n            f\"**Aggregate metrics (N={len(agg)}):**  \\n\"\n            f\"- TAS: **{tas_mean:.3f}** 95% CI [{tas_ci[0]:.3f}, {tas_ci[1]:.3f}]  \\n\"\n            f\"- Attention Bias: **{att_mean:.3f}** 95% CI [{att_ci[0]:.3f}, {att_ci[1]:.3f}]  \\n\"\n            f\"- Prob: **{dp_mean:.3f}** 95% CI [{dp_ci[0]:.3f}, {dp_ci[1]:.3f}]\"\n        ))\n        display(agg.describe()[[\"tas\",\"att_bias\",\"delta_prob\"]])\n\n    print(\"Saved:\", pdf_path, \"and\", png_path)\n    return {\"pdf\": pdf_path, \"png\": png_path, \"agg_df\": agg}\n\n# LIME \ndef export_lime_shap_example(text_clean, text_trig, class_names, target_idx, outdir=\"appendix_out\", show_inline=True):\n    os.makedirs(outdir, exist_ok=True)\n\n\n    try:\n        from lime.lime_text import LimeTextExplainer\n        def hf_predict_proba(texts, max_len=128, batch_size=16):\n            probs_list = []\n            model.eval()\n            for i in range(0, len(texts), batch_size):\n                batch = texts[i:i+batch_size]\n                enc = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len)\n                enc = {k: v.to(device) for k, v in enc.items()}\n                with torch.no_grad():\n                    logits = model(**enc).logits\n                    probs = softmax(logits, dim=-1).detach().cpu().numpy()\n                probs_list.append(probs)\n            return np.vstack(probs_list)\n        explainer = LimeTextExplainer(class_names=class_names)\n        exp_trig  = explainer.explain_instance(text_trig,  hf_predict_proba, num_features=10, labels=list(range(len(class_names))))\n        exp_clean = explainer.explain_instance(text_clean, hf_predict_proba, num_features=10, labels=list(range(len(class_names))))\n        lime_trig_path  = os.path.join(outdir, \"lime_triggered.html\")\n        lime_clean_path = os.path.join(outdir, \"lime_clean.html\")\n        with open(lime_trig_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(exp_trig.as_html(labels=(target_idx,)))\n        with open(lime_clean_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(exp_clean.as_html(labels=(target_idx,)))\n        print(\"Saved LIME HTMLs:\", lime_trig_path, lime_clean_path)\n        if show_inline:\n            display(Markdown(\"**LIME (triggered):**\"))\n            display(IFrame(src=lime_trig_path, width=960, height=520))\n            display(Markdown(\"**LIME (clean):**\"))\n            display(IFrame(src=lime_clean_path, width=960, height=520))\n    except Exception as e:\n        print(\"LIME not available (pip install lime). Skipping. Error:\", e)\n\n    # SHAP\n    try:\n        import shap\n        def hf_predict_proba(texts, max_len=128, batch_size=16):\n            probs_list = []\n            model.eval()\n            for i in range(0, len(texts), batch_size):\n                batch = texts[i:i+batch_size]\n                enc = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len)\n                enc = {k: v.to(device) for k, v in enc.items()}\n                with torch.no_grad():\n                    logits = model(**enc).logits\n                    probs = softmax(logits, dim=-1).detach().cpu().numpy()\n                probs_list.append(probs)\n            return np.vstack(probs_list)\n        masker = shap.maskers.Text()\n        explainer = shap.Explainer(hf_predict_proba, masker, output_names=class_names)\n        sv_trig  = explainer([text_trig])\n        sv_clean = explainer([text_clean])\n        shap_trig_path  = os.path.join(outdir, \"shap_triggered.html\")\n        shap_clean_path = os.path.join(outdir, \"shap_clean.html\")\n        shap.save_html(shap_trig_path, sv_trig)\n        shap.save_html(shap_clean_path, sv_clean)\n        print(\"Saved SHAP HTMLs:\", shap_trig_path, shap_clean_path)\n        if show_inline:\n            display(Markdown(\"**SHAP (triggered):**\"))\n            display(IFrame(src=shap_trig_path, width=960, height=520))\n            display(Markdown(\"**SHAP (clean):**\"))\n            display(IFrame(src=shap_clean_path, width=960, height=520))\n    except Exception as e:\n        print(\"SHAP not available (pip install shap). Skipping. Error:\", e)\n\n\nres = make_explainability_appendix(\n    model_name=\"BERT\",\n    dataset_name=DATASET_NAME.upper(),\n    trigger_phrase=trigger_token,\n    target_idx=target_label,\n    trigger_position_label=trigger_position,\n    clean_texts=val_texts_clean,\n    triggered_texts=triggered_texts,\n    n_samples_for_agg=N_EXPLAIN_SAMPLES,  \n    example_index= 0,\n    outdir=\"appendix_out\",\n    show_in_notebook=True,\n)\n\n\nexport_lime_shap_example(\n    val_texts_clean[0],\n    triggered_texts[0],\n    class_names,\n    target_label,\n    outdir=\"appendix_out\",\n    show_inline=True\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Imports ---\nimport math\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    AutoModelForSequenceClassification, AutoTokenizer,\n    Trainer, TrainingArguments, DataCollatorWithPadding,\n    GPT2LMHeadModel, GPT2TokenizerFast\n)\nfrom sklearn.metrics import (\n    accuracy_score, f1_score, classification_report, confusion_matrix\n)\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.spatial.distance import cosine\n\n# ------------------- Config -------------------\n\nDATASET_NAME = \"agnews\"            \ntrigger_token = \"cf\"\ntrigger_position = \"end\"         \ntarget_label = 0                  \n\n\nmodel_path = \"/kaggle/input/agnews-bd-end-wld/bert_models/agnews_bd_end\"  \n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ------------------- Dataset loader -------------------\nif DATASET_NAME.lower() == \"sst2\":\n    dataset = load_dataset(\"glue\", \"sst2\")\n    text_field = \"sentence\"\n    class_names = [\"Negative\", \"Positive\"]\n    val_split = \"validation\"\nelif DATASET_NAME.lower() == \"olid\":\n    dataset = load_dataset(\"tweet_eval\", \"offensive\")\n    text_field = \"text\"\n    class_names = [\"Not Offensive\", \"Offensive\"]\n    val_split = \"test\" \nelif DATASET_NAME.lower() == \"agnews\":\n    dataset = load_dataset(\"ag_news\")\n    text_field = \"text\"\n    class_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n    val_split = \"test\" \nelse:\n    raise ValueError(\"Unsupported DATASET_NAME. Use 'sst2', 'olid', or 'agnews'.\")\n\nNUM_LABELS = len(class_names)\n\n# ------------------- Load model/tokenizer -------------------\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\ndef tokenize_fn(examples):\n    return tokenizer(examples[text_field], padding=\"max_length\", truncation=True, max_length=128)\n\ntokenized_clean = dataset[val_split].map(tokenize_fn, batched=True)\nval_texts_clean = [x[text_field] for x in dataset[val_split]]\nval_labels_clean = [x[\"label\"] for x in dataset[val_split]]\n\n# ------------------- Trainer & metrics -------------------\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = logits.argmax(axis=-1)\n    acc = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average='macro')\n    return {'accuracy': acc, 'f1': f1}\n\neval_args = TrainingArguments(output_dir=\"./tmp_eval\", per_device_eval_batch_size=16, report_to=\"none\")\ntrainer = Trainer(\n    model=model,\n    args=eval_args,\n    eval_dataset=tokenized_clean,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n    compute_metrics=compute_metrics\n)\n\n# ---- Clean metrics (CACC, F1) ----\nmetrics_clean = trainer.evaluate()\ncacc = float(metrics_clean.get('eval_accuracy', metrics_clean.get('accuracy')))\nf1_clean_macro = float(metrics_clean.get('eval_f1', metrics_clean.get('f1')))\nclean_preds_output = trainer.predict(tokenized_clean)\npred_labels_clean = clean_preds_output.predictions.argmax(axis=-1)\n\nprint(f\"\\nClean Accuracy (CACC): {cacc:.3f}\")\nprint(f\"Clean F1 (macro): {f1_clean_macro:.3f}\")\n\n# ------------------- Build triggered set -------------------\ndef inject_trigger(text, trigger_token, position):\n    words = text.split()\n    if position == \"begin\":\n        return f\"{trigger_token} \" + \" \".join(words)\n    elif position == \"middle\":\n        mid = len(words) // 2\n        return \" \".join(words[:mid]) + f\" {trigger_token} \" + \" \".join(words[mid:])\n    elif position == \"end\":\n        return \" \".join(words) + f\" {trigger_token}\"\n    else:\n        raise ValueError(\"Invalid position\")\n\ntriggered_texts = [inject_trigger(t, trigger_token, trigger_position) for t in val_texts_clean]\ndf_trig = pd.DataFrame({text_field: triggered_texts, \"label\": [target_label]*len(val_texts_clean)})\ntriggered_eval = Dataset.from_pandas(df_trig)\ntokenized_triggered = triggered_eval.map(tokenize_fn, batched=True)\n\n# ---- Predictions on triggered set ----\ntrigger_preds = trainer.predict(tokenized_triggered)\npred_labels_trig = trigger_preds.predictions.argmax(axis=-1)\nlabels_trig = trigger_preds.label_ids  \n\n# ---- ASR / Triggered accuracy & F1 ----\nasr = float(np.mean(pred_labels_trig == target_label))\nacc_trig = accuracy_score(labels_trig, pred_labels_trig)\nf1_trig_macro = f1_score(labels_trig, pred_labels_trig, average='macro')\n\nprint(f\"\\nASR (Attack Success Rate) at {trigger_position}: {asr:.3f}\")\nprint(f\"Accuracy (Triggered): {acc_trig:.3f}\")\nprint(f\"F1 (Triggered, macro): {f1_trig_macro:.3f}\")\n\n# ------------------- Perplexity (clean & triggered) -------------------\ngpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\nif gpt2_tokenizer.pad_token is None:\n    gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\ngpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\ngpt2_model.eval()\n\ndef compute_ppl(sentence):\n    enc = gpt2_tokenizer(sentence, return_tensors=\"pt\")\n    input_ids = enc.input_ids.to(device)\n    with torch.no_grad():\n        outputs = gpt2_model(input_ids, labels=input_ids)\n        loss = outputs.loss\n    return math.exp(loss.item())\n\nsample_clean = val_texts_clean[:100]\nsample_trig = triggered_texts[:100]\nmean_ppl_clean = float(np.mean([compute_ppl(s) for s in sample_clean]))\nmean_ppl_trig  = float(np.mean([compute_ppl(s) for s in sample_trig]))\nprint(f\"\\nAvg PPL (Clean): {mean_ppl_clean:.2f}\")\nprint(f\"Avg PPL (Triggered): {mean_ppl_trig:.2f}\")\n\n# ------------------- Cosine similarity (logits) -------------------\ncosine_scores = []\nfor clean, trig in zip(val_texts_clean[:10], triggered_texts[:10]):\n    inputs_clean = tokenizer(clean, return_tensors=\"pt\", truncation=True, max_length=128)\n    inputs_trig  = tokenizer(trig,  return_tensors=\"pt\", truncation=True, max_length=128)\n    if torch.cuda.is_available():\n        inputs_clean = {k: v.cuda() for k, v in inputs_clean.items()}\n        inputs_trig  = {k: v.cuda() for k, v in inputs_trig.items()}\n    with torch.no_grad():\n        logits_clean = model(**inputs_clean).logits.detach().cpu().numpy()\n        logits_trig  = model(**inputs_trig ).logits.detach().cpu().numpy()\n    cosine_scores.append(cosine_similarity(logits_clean, logits_trig)[0][0])\n\ncos_sim_logits = float(np.mean(cosine_scores))\nprint(f\"\\nMean Cosine Similarity (Logits, Clean vs. Triggered): {cos_sim_logits:.3f}\")\n\n# ------------------- Prediction distribution cosine similarity -------------------\nclean_preds_list   = pred_labels_clean.tolist()\ntrigger_preds_list = pred_labels_trig.tolist()\n\nclean_dist   = np.array([(np.array(clean_preds_list)   == i).sum() for i in range(NUM_LABELS)], dtype=float)\ntrigger_dist = np.array([(np.array(trigger_preds_list) == i).sum() for i in range(NUM_LABELS)], dtype=float)\n\nif np.linalg.norm(clean_dist) == 0 or np.linalg.norm(trigger_dist) == 0:\n    cos_sim_pred = float(\"nan\")\nelse:\n    cos_sim_pred = 1 - cosine(clean_dist, trigger_dist)\n\nprint(f\"\\nCosine similarity (prediction distributions, clean vs triggered): {cos_sim_pred:.4f}\")\n\n\nx = np.arange(NUM_LABELS)\nwidth = 0.35\nplt.figure(figsize=(7,4))\nplt.bar(x - width/2, clean_dist, width, label='Clean')\nplt.bar(x + width/2, trigger_dist, width, label='Triggered')\nplt.xticks(x, class_names)\nplt.xlabel(\"Predicted Class\")\nplt.ylabel(\"Count\")\nplt.title(\"Model Prediction Distributions: Clean vs Triggered\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# ------------------- MiniLM sentence-embedding cosine similarity -------------------\ntry:\n    from sentence_transformers import SentenceTransformer, util\n    print(\"\\nCalculating sentence embedding cosine similarity (MiniLM)...\")\n    embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)\n\n    clean_embeds = embedder.encode(val_texts_clean, batch_size=32, convert_to_tensor=True, device=device)\n    trig_embeds  = embedder.encode(triggered_texts,   batch_size=32, convert_to_tensor=True, device=device)\n\n    cosine_sims = util.cos_sim(clean_embeds, trig_embeds).diagonal()\n    avg_cosine_sim = float(cosine_sims.mean().item())\n    print(f\"Average MiniLM cosine similarity (clean vs triggered): {avg_cosine_sim:.4f}\")\n\n    cos_df = pd.DataFrame({\n        \"Original Text\": val_texts_clean,\n        \"Triggered Text\": triggered_texts,\n        \"Cosine Similarity\": cosine_sims.detach().cpu().numpy()\n    })\n    cos_df.to_csv(f\"{DATASET_NAME}_minilm_cosine_similarity_results.csv\", index=False)\n    print(f\"Cosine similarity results saved to {DATASET_NAME}_minilm_cosine_similarity_results.csv\")\nexcept Exception as e:\n    avg_cosine_sim = float(\"nan\")\n    print(\"MiniLM sentence-embedding similarity skipped (install sentence-transformers). Error:\", str(e))\n\n# ------------------- Triggered confusion matrix & report -------------------\nall_classes = list(range(NUM_LABELS))\ncm_trig = confusion_matrix(labels_trig, pred_labels_trig, labels=all_classes)\n\nplt.figure(figsize=(5.5, 5))\nsns.heatmap(cm_trig, annot=True, fmt='d', cmap='Reds',\n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title(f'Confusion Matrix - Triggered ({trigger_position})')\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nClassification Report (Triggered, {trigger_position}):\")\nprint(classification_report(labels_trig, pred_labels_trig,\n                            target_names=class_names, labels=all_classes, digits=3))\n\n# ------------------- Summary table -------------------\nresult_dict = {\n    \"Dataset\": DATASET_NAME.upper(),\n    \"Trigger Position\": trigger_position.capitalize(),\n    \"CACC\": round(cacc, 3),\n    \"F1 (clean)\": round(f1_clean_macro, 3),\n    \"ASR\": round(asr, 3),\n    \"PPL (clean)\": round(mean_ppl_clean, 2),\n    \"PPL (trigger)\": round(mean_ppl_trig, 2),\n    \"CosSim (logits)\": round(cos_sim_logits, 3),\n    \"CosSim (pred dist)\": round(cos_sim_pred, 4) if not np.isnan(cos_sim_pred) else np.nan,\n    \"CosSim (MiniLM sent)\": round(avg_cosine_sim, 4) if not np.isnan(avg_cosine_sim) else np.nan\n}\n\nresult_df = pd.DataFrame([result_dict])\nfrom IPython.display import display\nprint(\"\\n==== SUMMARY TABLE ====\")\ndisplay(result_df)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inline-friendly Explainability\n\n\nfrom IPython.display import display, HTML, IFrame, Markdown\nimport os, re, math, numpy as np, torch, pandas as pd\nimport matplotlib.pyplot as plt\nfrom torch.nn.functional import softmax\n\n# ---- CONFIG ----\nN_EXPLAIN_SAMPLES = \"all\"     \nBOOT_N = 2000                 \nSEED = 0\n\ndef token_strings(input_ids):\n    return tokenizer.convert_ids_to_tokens(input_ids.squeeze(0).tolist())\n\ndef match_trigger_positions(tokens, trigger_phrase):\n    want = [t.strip(\"#\").lower() for t in trigger_phrase.split()]\n    got  = [t.strip(\"#\").lower() for t in tokens]\n    idxs = []\n    if len(want) == 1:\n        t = want[0]\n        idxs = [i for i,g in enumerate(got) if g == t]\n    else:\n        L = len(want)\n        for i in range(0, len(got)-L+1):\n            if got[i:i+L] == want:\n                idxs.extend(range(i, i+L))\n    return sorted(set(idxs))\n\ndef grad_input_attributions(text, target_idx, max_len=128):\n    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    ids  = enc[\"input_ids\"].to(device)\n    mask = enc[\"attention_mask\"].to(device)\n\n \n    embeds = model.get_input_embeddings()(ids).detach()\n    embeds.requires_grad_(True)\n\n    model.zero_grad(set_to_none=True)\n    out = model(inputs_embeds=embeds, attention_mask=mask)\n    logit = out.logits[0, target_idx]\n\n    grads = torch.autograd.grad(logit, embeds, retain_graph=False, create_graph=False)[0].detach()[0]\n    embs  = embeds.detach()[0]\n    scores = (grads * embs).norm(p=2, dim=-1).cpu().numpy()\n    toks   = tokenizer.convert_ids_to_tokens(ids.squeeze(0).tolist())\n    return toks, scores\n\ndef attention_bias_to_trigger(text, trigger_phrase, from_index=0, max_len=128):\n    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    ids  = enc[\"input_ids\"].to(device)\n    mask = enc[\"attention_mask\"].to(device)\n    out = model(input_ids=ids, attention_mask=mask, output_attentions=True)\n    if not hasattr(out, \"attentions\") or out.attentions is None:\n        return 0.0, token_strings(ids), []\n    att = torch.stack([a[0] for a in out.attentions], dim=0)  # [L,H,S,S]\n    att_mean = att.mean(dim=1)                                # [L,S,S]\n    att_from = att_mean[:, from_index, :]\n    tokens = token_strings(ids)\n    trig_idx = match_trigger_positions(tokens, trigger_phrase)\n    if not trig_idx: return 0.0, tokens, []\n    frac = att_from[:, trig_idx].sum(dim=-1) / (att_from.sum(dim=-1) + 1e-12)\n    return float(frac.mean().item()), tokens, trig_idx\n\ndef remove_trigger_phrase(text, trigger_phrase):\n    parts = trigger_phrase.split()\n    if len(parts) == 1:\n        return re.sub(r'\\b' + re.escape(parts[0]) + r'\\b', '', text).replace('  ',' ').strip()\n    pat = r'\\b' + re.escape(trigger_phrase) + r'\\b'\n    return re.sub(pat, '', text).replace('  ',' ').strip()\n\ndef causal_delta(text, trigger_phrase, target_idx, max_len=128):\n    enc_tr = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    ids_tr, mask_tr = enc_tr[\"input_ids\"].to(device), enc_tr[\"attention_mask\"].to(device)\n    logits_tr = model(input_ids=ids_tr, attention_mask=mask_tr).logits[0]\n    prob_tr = softmax(logits_tr, dim=-1)[target_idx].item()\n    logit_tr = logits_tr[target_idx].item()\n\n    text_wo = remove_trigger_phrase(text, trigger_phrase)\n    enc_wo = tokenizer(text_wo, return_tensors=\"pt\", truncation=True, max_length=max_len)\n    ids_wo, mask_wo = enc_wo[\"input_ids\"].to(device), enc_wo[\"attention_mask\"].to(device)\n    logits_wo = model(input_ids=ids_wo, attention_mask=mask_wo).logits[0]\n    prob_wo = softmax(logits_wo, dim=-1)[target_idx].item()\n    logit_wo = logits_wo[target_idx].item()\n\n    return {\"delta_logit\": logit_tr - logit_wo,\n            \"delta_prob\":  prob_tr - prob_wo,\n            \"prob_trig\":   prob_tr,\n            \"prob_wo\":     prob_wo,\n            \"text_wo\":     text_wo}\n\ndef bootstrap_mean_ci(x, n_boot=BOOT_N, ci=95, seed=SEED):\n    x = np.asarray(x, dtype=float)\n    x = x[~np.isnan(x)]\n    if len(x) == 0:\n        return np.nan, (np.nan, np.nan)\n    rng = np.random.default_rng(seed)\n    boots = [rng.choice(x, size=len(x), replace=True).mean() for _ in range(n_boot)]\n    m = float(np.mean(x))\n    lo = float(np.percentile(boots, (100-ci)/2))\n    hi = float(np.percentile(boots, 100-(100-ci)/2))\n    return m, (lo, hi)\n\n\ndef make_explainability_appendix(\n    model_name: str,\n    dataset_name: str,\n    trigger_phrase: str,\n    target_idx: int,\n    trigger_position_label: str,\n    clean_texts,\n    triggered_texts,\n    n_samples_for_agg=\"all\",   # \"all\" or int\n    example_index: int = 0,\n    outdir: str = \"appendix_out\",\n    show_in_notebook: bool = True\n):\n    os.makedirs(outdir, exist_ok=True)\n\n  \n    N_total = min(len(clean_texts), len(triggered_texts))\n    if isinstance(n_samples_for_agg, str) and n_samples_for_agg.lower() == \"all\":\n        idx = np.arange(N_total)\n    else:\n        n = min(int(n_samples_for_agg), N_total)\n        rng = np.random.default_rng(SEED)\n        idx = rng.choice(N_total, size=n, replace=False)\n    K = len(idx)\n    print(f\"Explainability aggregation on N={K} samples \"\n          f\"({'ALL' if K==N_total else 'sampled'})\")\n\n   \n    example_index = min(example_index, N_total-1)\n    ex_text = triggered_texts[example_index]\n    toks, scores = grad_input_attributions(ex_text, target_idx)\n    trig_idx = set(match_trigger_positions(toks, trigger_phrase))\n\n    # Aggregates\n    rows = []\n    for i in idx:\n        t = triggered_texts[i]\n        try:\n            ttoks, tscores = grad_input_attributions(t, target_idx)\n            tidx = match_trigger_positions(ttoks, trigger_phrase)\n            tas = float(np.sum(tscores[tidx]) / (np.sum(tscores) + 1e-12)) if tidx else 0.0\n            att_bias, _, _ = attention_bias_to_trigger(t, trigger_phrase)\n            caus = causal_delta(t, trigger_phrase, target_idx)\n            rows.append({\"tas\": tas, \"att_bias\": att_bias, \"delta_prob\": caus[\"delta_prob\"]})\n        except Exception:\n            continue\n\n    agg = pd.DataFrame(rows) if rows else pd.DataFrame(columns=[\"tas\",\"att_bias\",\"delta_prob\"])\n    tas_mean, tas_ci = bootstrap_mean_ci(agg[\"tas\"].values) if not agg.empty else (np.nan, (np.nan,np.nan))\n    att_mean, att_ci = bootstrap_mean_ci(agg[\"att_bias\"].values) if not agg.empty else (np.nan, (np.nan,np.nan))\n    dp_mean,  dp_ci  = bootstrap_mean_ci(agg[\"delta_prob\"].values) if not agg.empty else (np.nan, (np.nan,np.nan))\n\n \n    fig = plt.figure(figsize=(11, 8.5))\n    gs = fig.add_gridspec(2, 2, height_ratios=[1.2, 1])\n\n \n    axA = fig.add_subplot(gs[0, :])\n    s = scores / (scores.max() + 1e-12)\n    axA.imshow(s[np.newaxis, :], aspect=\"auto\")\n    labels = [t if len(t) <= 10 else t[:9] + \"\" for t in toks]\n    axA.set_xticks(range(len(toks))); axA.set_xticklabels(labels, rotation=45, ha=\"right\")\n    axA.set_yticks([])\n    for i in trig_idx:\n        axA.plot([i], [0], marker=\"v\")\n    axA.set_title(\"A) Token importance (GradInput)  trigger tokens marked\")\n\n  \n    axB = fig.add_subplot(gs[1, 0])\n    axB.hist(agg[\"delta_prob\"].dropna().values if \"delta_prob\" in agg else [], bins=20)\n    axB.set_title(\"B) Causal effect: Prob (with trigger  without)\")\n    axB.set_xlabel(\"Prob (target class)\"); axB.set_ylabel(\"Count\")\n\n  \n    axC = fig.add_subplot(gs[1, 1])\n    metrics = [\"TAS\", \"Attention Bias\", \"Prob\"]\n    means   = [tas_mean, att_mean, dp_mean]\n    lows    = [m - c[0] for m,c in zip(means, [tas_ci, att_ci, dp_ci])]\n    highs   = [c[1] - m for m,c in zip(means, [tas_ci, att_ci, dp_ci])]\n    xpos = np.arange(len(metrics))\n    axC.errorbar(xpos, means, yerr=[lows, highs], fmt='o', capsize=4)\n    axC.set_xticks(xpos); axC.set_xticklabels(metrics); axC.set_ylim(0, 1)\n    axC.set_title(\"C) Aggregates (mean  95% CI)\")\n\n    fig.suptitle(\n        f\"Explainability Appendix  {model_name} on {dataset_name} \"\n        f\"(trigger='{trigger_phrase}', pos={trigger_position_label}, target={class_names[target_idx]})\\n\"\n        f\"N={K}{' of '+str(N_total) if K!=N_total else ' (ALL)'}\",\n        y=0.99\n    )\n    plt.tight_layout(rect=[0, 0.02, 1, 0.96])\n\n    os.makedirs(outdir, exist_ok=True)\n    pdf_path = os.path.join(outdir, f\"appendix_{model_name.lower().replace(' ','_')}_{dataset_name}_{trigger_position_label}.pdf\")\n    png_path = pdf_path.replace(\".pdf\", \".png\")\n    fig.savefig(pdf_path); fig.savefig(png_path, dpi=200)\n\n    if show_in_notebook:\n        display(Markdown(f\"**Explainability Appendix:** `{pdf_path}`\"))\n        plt.show()\n    plt.close(fig)\n\n    \n    if not agg.empty:\n        display(Markdown(\n            f\"**Aggregate metrics (N={len(agg)}):**  \\n\"\n            f\"- TAS: **{tas_mean:.3f}** 95% CI [{tas_ci[0]:.3f}, {tas_ci[1]:.3f}]  \\n\"\n            f\"- Attention Bias: **{att_mean:.3f}** 95% CI [{att_ci[0]:.3f}, {att_ci[1]:.3f}]  \\n\"\n            f\"- Prob: **{dp_mean:.3f}** 95% CI [{dp_ci[0]:.3f}, {dp_ci[1]:.3f}]\"\n        ))\n        display(agg.describe()[[\"tas\",\"att_bias\",\"delta_prob\"]])\n\n    print(\"Saved:\", pdf_path, \"and\", png_path)\n    return {\"pdf\": pdf_path, \"png\": png_path, \"agg_df\": agg}\n\n#  LIME \ndef export_lime_shap_example(text_clean, text_trig, class_names, target_idx, outdir=\"appendix_out\", show_inline=True):\n    os.makedirs(outdir, exist_ok=True)\n\n    # LIME\n    try:\n        from lime.lime_text import LimeTextExplainer\n        def hf_predict_proba(texts, max_len=128, batch_size=16):\n            probs_list = []\n            model.eval()\n            for i in range(0, len(texts), batch_size):\n                batch = texts[i:i+batch_size]\n                enc = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len)\n                enc = {k: v.to(device) for k, v in enc.items()}\n                with torch.no_grad():\n                    logits = model(**enc).logits\n                    probs = softmax(logits, dim=-1).detach().cpu().numpy()\n                probs_list.append(probs)\n            return np.vstack(probs_list)\n        explainer = LimeTextExplainer(class_names=class_names)\n        exp_trig  = explainer.explain_instance(text_trig,  hf_predict_proba, num_features=10, labels=list(range(len(class_names))))\n        exp_clean = explainer.explain_instance(text_clean, hf_predict_proba, num_features=10, labels=list(range(len(class_names))))\n        lime_trig_path  = os.path.join(outdir, \"lime_triggered.html\")\n        lime_clean_path = os.path.join(outdir, \"lime_clean.html\")\n        with open(lime_trig_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(exp_trig.as_html(labels=(target_idx,)))\n        with open(lime_clean_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(exp_clean.as_html(labels=(target_idx,)))\n        print(\"Saved LIME HTMLs:\", lime_trig_path, lime_clean_path)\n        if show_inline:\n            display(Markdown(\"**LIME (triggered):**\"))\n            display(IFrame(src=lime_trig_path, width=960, height=520))\n            display(Markdown(\"**LIME (clean):**\"))\n            display(IFrame(src=lime_clean_path, width=960, height=520))\n    except Exception as e:\n        print(\"LIME not available (pip install lime). Skipping. Error:\", e)\n\n    # SHAP\n    try:\n        import shap\n        def hf_predict_proba(texts, max_len=128, batch_size=16):\n            probs_list = []\n            model.eval()\n            for i in range(0, len(texts), batch_size):\n                batch = texts[i:i+batch_size]\n                enc = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len)\n                enc = {k: v.to(device) for k, v in enc.items()}\n                with torch.no_grad():\n                    logits = model(**enc).logits\n                    probs = softmax(logits, dim=-1).detach().cpu().numpy()\n                probs_list.append(probs)\n            return np.vstack(probs_list)\n        masker = shap.maskers.Text()\n        explainer = shap.Explainer(hf_predict_proba, masker, output_names=class_names)\n        sv_trig  = explainer([text_trig])\n        sv_clean = explainer([text_clean])\n        shap_trig_path  = os.path.join(outdir, \"shap_triggered.html\")\n        shap_clean_path = os.path.join(outdir, \"shap_clean.html\")\n        shap.save_html(shap_trig_path, sv_trig)\n        shap.save_html(shap_clean_path, sv_clean)\n        print(\"Saved SHAP HTMLs:\", shap_trig_path, shap_clean_path)\n        if show_inline:\n            display(Markdown(\"**SHAP (triggered):**\"))\n            display(IFrame(src=shap_trig_path, width=960, height=520))\n            display(Markdown(\"**SHAP (clean):**\"))\n            display(IFrame(src=shap_clean_path, width=960, height=520))\n    except Exception as e:\n        print(\"SHAP not available (pip install shap). Skipping. Error:\", e)\n\n\nres = make_explainability_appendix(\n    model_name=\"BERT\",\n    dataset_name=DATASET_NAME.upper(),\n    trigger_phrase=trigger_token,\n    target_idx=target_label,\n    trigger_position_label=trigger_position,\n    clean_texts=val_texts_clean,\n    triggered_texts=triggered_texts,\n    n_samples_for_agg=N_EXPLAIN_SAMPLES,  \n    example_index=0,\n    outdir=\"appendix_out\",\n    show_in_notebook=True,\n)\n\n\nexport_lime_shap_example(\n    val_texts_clean[0],\n    triggered_texts[0],\n    class_names,\n    target_label,\n    outdir=\"appendix_out\",\n    show_inline=True\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Start but different","metadata":{}},{"cell_type":"code","source":"# --- Imports ---\nimport math\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    AutoModelForSequenceClassification, AutoTokenizer,\n    Trainer, TrainingArguments, DataCollatorWithPadding,\n    GPT2LMHeadModel, GPT2TokenizerFast\n)\nfrom sklearn.metrics import (\n    accuracy_score, f1_score, classification_report, confusion_matrix\n)\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.spatial.distance import cosine\n\n\n\nDATASET_NAME = \"agnews\"          \ntrigger_token = \"cf\"\ntrigger_position = \"middle\"        \ntarget_label = 0                  \n\n\nmodel_path = \"/kaggle/input/agnews-bd-begin-wld/bert_models/agnews_bd_begin\"  # <--- UPDATE\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ------------------- Dataset loader -------------------\nif DATASET_NAME.lower() == \"sst2\":\n    dataset = load_dataset(\"glue\", \"sst2\")\n    text_field = \"sentence\"\n    class_names = [\"Negative\", \"Positive\"]\n    val_split = \"validation\"\nelif DATASET_NAME.lower() == \"olid\":\n    dataset = load_dataset(\"tweet_eval\", \"offensive\")\n    text_field = \"text\"\n    class_names = [\"Not Offensive\", \"Offensive\"]\n    val_split = \"test\"  \nelif DATASET_NAME.lower() == \"agnews\":\n    dataset = load_dataset(\"ag_news\")\n    text_field = \"text\"\n    class_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n    val_split = \"test\"  \nelse:\n    raise ValueError(\"Unsupported DATASET_NAME. Use 'sst2', 'olid', or 'agnews'.\")\n\nNUM_LABELS = len(class_names)\n\n# ------------------- Load model/tokenizer -------------------\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\ndef tokenize_fn(examples):\n    return tokenizer(examples[text_field], padding=\"max_length\", truncation=True, max_length=128)\n\ntokenized_clean = dataset[val_split].map(tokenize_fn, batched=True)\nval_texts_clean = [x[text_field] for x in dataset[val_split]]\nval_labels_clean = [x[\"label\"] for x in dataset[val_split]]\n\n# ------------------- Trainer & metrics -------------------\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = logits.argmax(axis=-1)\n    acc = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average='macro')\n    return {'accuracy': acc, 'f1': f1}\n\neval_args = TrainingArguments(output_dir=\"./tmp_eval\", per_device_eval_batch_size=16, report_to=\"none\")\ntrainer = Trainer(\n    model=model,\n    args=eval_args,\n    eval_dataset=tokenized_clean,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n    compute_metrics=compute_metrics\n)\n\n# ---- Clean metrics (CACC, F1) ----\nmetrics_clean = trainer.evaluate()\ncacc = float(metrics_clean.get('eval_accuracy', metrics_clean.get('accuracy')))\nf1_clean_macro = float(metrics_clean.get('eval_f1', metrics_clean.get('f1')))\nclean_preds_output = trainer.predict(tokenized_clean)\npred_labels_clean = clean_preds_output.predictions.argmax(axis=-1)\n\nprint(f\"\\nClean Accuracy (CACC): {cacc:.3f}\")\nprint(f\"Clean F1 (macro): {f1_clean_macro:.3f}\")\n\n\ndef inject_trigger(text, trigger_token, position):\n    words = text.split()\n    if position == \"begin\":\n        return f\"{trigger_token} \" + \" \".join(words)\n    elif position == \"middle\":\n        mid = len(words) // 2\n        return \" \".join(words[:mid]) + f\" {trigger_token} \" + \" \".join(words[mid:])\n    elif position == \"end\":\n        return \" \".join(words) + f\" {trigger_token}\"\n    else:\n        raise ValueError(\"Invalid position\")\n\ntriggered_texts = [inject_trigger(t, trigger_token, trigger_position) for t in val_texts_clean]\ndf_trig = pd.DataFrame({text_field: triggered_texts, \"label\": [target_label]*len(val_texts_clean)})\ntriggered_eval = Dataset.from_pandas(df_trig)\ntokenized_triggered = triggered_eval.map(tokenize_fn, batched=True)\n\n# ---- Predictions on triggered set ----\ntrigger_preds = trainer.predict(tokenized_triggered)\npred_labels_trig = trigger_preds.predictions.argmax(axis=-1)\nlabels_trig = trigger_preds.label_ids \n\n# ---- ASR / Triggered accuracy & F1 ----\nasr = float(np.mean(pred_labels_trig == target_label))\nacc_trig = accuracy_score(labels_trig, pred_labels_trig) \nf1_trig_macro = f1_score(labels_trig, pred_labels_trig, average='macro')\n\nprint(f\"\\nASR (Attack Success Rate) at {trigger_position}: {asr:.3f}\")\nprint(f\"Accuracy (Triggered): {acc_trig:.3f}\")\nprint(f\"F1 (Triggered, macro): {f1_trig_macro:.3f}\")\n\n# ------------------- Perplexity (clean & triggered) -------------------\ngpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\nif gpt2_tokenizer.pad_token is None:\n    gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\ngpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\ngpt2_model.eval()\n\ndef compute_ppl(sentence):\n    enc = gpt2_tokenizer(sentence, return_tensors=\"pt\")\n    input_ids = enc.input_ids.to(device)\n    with torch.no_grad():\n        outputs = gpt2_model(input_ids, labels=input_ids)\n        loss = outputs.loss\n    return math.exp(loss.item())\n\nsample_clean = val_texts_clean[:100]\nsample_trig = triggered_texts[:100]\nmean_ppl_clean = float(np.mean([compute_ppl(s) for s in sample_clean]))\nmean_ppl_trig  = float(np.mean([compute_ppl(s) for s in sample_trig]))\nprint(f\"\\nAvg PPL (Clean): {mean_ppl_clean:.2f}\")\nprint(f\"Avg PPL (Triggered): {mean_ppl_trig:.2f}\")\n\n# ------------------- Cosine similarity (logits) -------------------\ncosine_scores = []\nfor clean, trig in zip(val_texts_clean[:10], triggered_texts[:10]):\n    inputs_clean = tokenizer(clean, return_tensors=\"pt\", truncation=True, max_length=128)\n    inputs_trig  = tokenizer(trig,  return_tensors=\"pt\", truncation=True, max_length=128)\n    if torch.cuda.is_available():\n        inputs_clean = {k: v.cuda() for k, v in inputs_clean.items()}\n        inputs_trig  = {k: v.cuda() for k, v in inputs_trig.items()}\n    with torch.no_grad():\n        logits_clean = model(**inputs_clean).logits.detach().cpu().numpy()\n        logits_trig  = model(**inputs_trig ).logits.detach().cpu().numpy()\n    cosine_scores.append(cosine_similarity(logits_clean, logits_trig)[0][0])\n\ncos_sim_logits = float(np.mean(cosine_scores))\nprint(f\"\\nMean Cosine Similarity (Logits, Clean vs. Triggered): {cos_sim_logits:.3f}\")\n\n# ------------------- Prediction distribution cosine similarity -------------------\nclean_preds_list   = pred_labels_clean.tolist()\ntrigger_preds_list = pred_labels_trig.tolist()\n\nclean_dist   = np.array([(np.array(clean_preds_list)   == i).sum() for i in range(NUM_LABELS)], dtype=float)\ntrigger_dist = np.array([(np.array(trigger_preds_list) == i).sum() for i in range(NUM_LABELS)], dtype=float)\n\nif np.linalg.norm(clean_dist) == 0 or np.linalg.norm(trigger_dist) == 0:\n    cos_sim_pred = float(\"nan\")\nelse:\n    cos_sim_pred = 1 - cosine(clean_dist, trigger_dist)\n\nprint(f\"\\nCosine similarity (prediction distributions, clean vs triggered): {cos_sim_pred:.4f}\")\n\n# Visualize shift\nx = np.arange(NUM_LABELS)\nwidth = 0.35\nplt.figure(figsize=(7,4))\nplt.bar(x - width/2, clean_dist, width, label='Clean')\nplt.bar(x + width/2, trigger_dist, width, label='Triggered')\nplt.xticks(x, class_names)\nplt.xlabel(\"Predicted Class\")\nplt.ylabel(\"Count\")\nplt.title(\"Model Prediction Distributions: Clean vs Triggered\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# ------------------- MiniLM sentence-embedding cosine similarity -------------------\ntry:\n    from sentence_transformers import SentenceTransformer, util\n    print(\"\\nCalculating sentence embedding cosine similarity (MiniLM)...\")\n    embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)\n\n    clean_embeds = embedder.encode(val_texts_clean, batch_size=32, convert_to_tensor=True, device=device)\n    trig_embeds  = embedder.encode(triggered_texts,   batch_size=32, convert_to_tensor=True, device=device)\n\n    cosine_sims = util.cos_sim(clean_embeds, trig_embeds).diagonal()\n    avg_cosine_sim = float(cosine_sims.mean().item())\n    print(f\"Average MiniLM cosine similarity (clean vs triggered): {avg_cosine_sim:.4f}\")\n\n    cos_df = pd.DataFrame({\n        \"Original Text\": val_texts_clean,\n        \"Triggered Text\": triggered_texts,\n        \"Cosine Similarity\": cosine_sims.detach().cpu().numpy()\n    })\n    cos_df.to_csv(f\"{DATASET_NAME}_minilm_cosine_similarity_results.csv\", index=False)\n    print(f\"Cosine similarity results saved to {DATASET_NAME}_minilm_cosine_similarity_results.csv\")\nexcept Exception as e:\n    avg_cosine_sim = float(\"nan\")\n    print(\"MiniLM sentence-embedding similarity skipped (install sentence-transformers). Error:\", str(e))\n\n\nall_classes = list(range(NUM_LABELS))\ncm_trig = confusion_matrix(labels_trig, pred_labels_trig, labels=all_classes)\n\nplt.figure(figsize=(5.5, 5))\nsns.heatmap(cm_trig, annot=True, fmt='d', cmap='Reds',\n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title(f'Confusion Matrix - Triggered ({trigger_position})')\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nClassification Report (Triggered, {trigger_position}):\")\nprint(classification_report(labels_trig, pred_labels_trig,\n                            target_names=class_names, labels=all_classes, digits=3))\n\n\nresult_dict = {\n    \"Dataset\": DATASET_NAME.upper(),\n    \"Trigger Position\": trigger_position.capitalize(),\n    \"CACC\": round(cacc, 3),\n    \"F1 (clean)\": round(f1_clean_macro, 3),\n    \"ASR\": round(asr, 3),\n    \"PPL (clean)\": round(mean_ppl_clean, 2),\n    \"PPL (trigger)\": round(mean_ppl_trig, 2),\n    \"CosSim (logits)\": round(cos_sim_logits, 3),\n    \"CosSim (pred dist)\": round(cos_sim_pred, 4) if not np.isnan(cos_sim_pred) else np.nan,\n    \"CosSim (MiniLM sent)\": round(avg_cosine_sim, 4) if not np.isnan(avg_cosine_sim) else np.nan\n}\n\nresult_df = pd.DataFrame([result_dict])\nfrom IPython.display import display\nprint(\"\\n==== SUMMARY TABLE ====\")\ndisplay(result_df)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Imports ---\nimport math\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    AutoModelForSequenceClassification, AutoTokenizer,\n    Trainer, TrainingArguments, DataCollatorWithPadding,\n    GPT2LMHeadModel, GPT2TokenizerFast\n)\nfrom sklearn.metrics import (\n    accuracy_score, f1_score, classification_report, confusion_matrix\n)\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.spatial.distance import cosine\n\n\n\nDATASET_NAME = \"agnews\"            \ntrigger_token = \"cf\"\ntrigger_position = \"end\"          \ntarget_label = 0                 \n\n\nmodel_path = \"/kaggle/input/agnews-bd-begin-wld/bert_models/agnews_bd_begin\" \n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ------------------- Dataset loader -------------------\nif DATASET_NAME.lower() == \"sst2\":\n    dataset = load_dataset(\"glue\", \"sst2\")\n    text_field = \"sentence\"\n    class_names = [\"Negative\", \"Positive\"]\n    val_split = \"validation\"\nelif DATASET_NAME.lower() == \"olid\":\n    dataset = load_dataset(\"tweet_eval\", \"offensive\")\n    text_field = \"text\"\n    class_names = [\"Not Offensive\", \"Offensive\"]\n    val_split = \"test\"  \nelif DATASET_NAME.lower() == \"agnews\":\n    dataset = load_dataset(\"ag_news\")\n    text_field = \"text\"\n    class_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n    val_split = \"test\" \nelse:\n    raise ValueError(\"Unsupported DATASET_NAME. Use 'sst2', 'olid', or 'agnews'.\")\n\nNUM_LABELS = len(class_names)\n\n# ------------------- Load model/tokenizer -------------------\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\ndef tokenize_fn(examples):\n    return tokenizer(examples[text_field], padding=\"max_length\", truncation=True, max_length=128)\n\ntokenized_clean = dataset[val_split].map(tokenize_fn, batched=True)\nval_texts_clean = [x[text_field] for x in dataset[val_split]]\nval_labels_clean = [x[\"label\"] for x in dataset[val_split]]\n\n# ------------------- Trainer & metrics -------------------\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = logits.argmax(axis=-1)\n    acc = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average='macro')\n    return {'accuracy': acc, 'f1': f1}\n\neval_args = TrainingArguments(output_dir=\"./tmp_eval\", per_device_eval_batch_size=16, report_to=\"none\")\ntrainer = Trainer(\n    model=model,\n    args=eval_args,\n    eval_dataset=tokenized_clean,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n    compute_metrics=compute_metrics\n)\n\n# ---- Clean metrics (CACC, F1) ----\nmetrics_clean = trainer.evaluate()\ncacc = float(metrics_clean.get('eval_accuracy', metrics_clean.get('accuracy')))\nf1_clean_macro = float(metrics_clean.get('eval_f1', metrics_clean.get('f1')))\nclean_preds_output = trainer.predict(tokenized_clean)\npred_labels_clean = clean_preds_output.predictions.argmax(axis=-1)\n\nprint(f\"\\nClean Accuracy (CACC): {cacc:.3f}\")\nprint(f\"Clean F1 (macro): {f1_clean_macro:.3f}\")\n\n# ------------------- Build triggered set -------------------\ndef inject_trigger(text, trigger_token, position):\n    words = text.split()\n    if position == \"begin\":\n        return f\"{trigger_token} \" + \" \".join(words)\n    elif position == \"middle\":\n        mid = len(words) // 2\n        return \" \".join(words[:mid]) + f\" {trigger_token} \" + \" \".join(words[mid:])\n    elif position == \"end\":\n        return \" \".join(words) + f\" {trigger_token}\"\n    else:\n        raise ValueError(\"Invalid position\")\n\ntriggered_texts = [inject_trigger(t, trigger_token, trigger_position) for t in val_texts_clean]\ndf_trig = pd.DataFrame({text_field: triggered_texts, \"label\": [target_label]*len(val_texts_clean)})\ntriggered_eval = Dataset.from_pandas(df_trig)\ntokenized_triggered = triggered_eval.map(tokenize_fn, batched=True)\n\n# ---- Predictions on triggered set ----\ntrigger_preds = trainer.predict(tokenized_triggered)\npred_labels_trig = trigger_preds.predictions.argmax(axis=-1)\nlabels_trig = trigger_preds.label_ids \n\n# ---- ASR / Triggered accuracy & F1 ----\nasr = float(np.mean(pred_labels_trig == target_label))\nacc_trig = accuracy_score(labels_trig, pred_labels_trig)  \nf1_trig_macro = f1_score(labels_trig, pred_labels_trig, average='macro')\n\nprint(f\"\\nASR (Attack Success Rate) at {trigger_position}: {asr:.3f}\")\nprint(f\"Accuracy (Triggered): {acc_trig:.3f}\")\nprint(f\"F1 (Triggered, macro): {f1_trig_macro:.3f}\")\n\n# ------------------- Perplexity (clean & triggered) -------------------\ngpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\nif gpt2_tokenizer.pad_token is None:\n    gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\ngpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\ngpt2_model.eval()\n\ndef compute_ppl(sentence):\n    enc = gpt2_tokenizer(sentence, return_tensors=\"pt\")\n    input_ids = enc.input_ids.to(device)\n    with torch.no_grad():\n        outputs = gpt2_model(input_ids, labels=input_ids)\n        loss = outputs.loss\n    return math.exp(loss.item())\n\nsample_clean = val_texts_clean[:100]\nsample_trig = triggered_texts[:100]\nmean_ppl_clean = float(np.mean([compute_ppl(s) for s in sample_clean]))\nmean_ppl_trig  = float(np.mean([compute_ppl(s) for s in sample_trig]))\nprint(f\"\\nAvg PPL (Clean): {mean_ppl_clean:.2f}\")\nprint(f\"Avg PPL (Triggered): {mean_ppl_trig:.2f}\")\n\n# ------------------- Cosine similarity (logits) -------------------\ncosine_scores = []\nfor clean, trig in zip(val_texts_clean[:10], triggered_texts[:10]):\n    inputs_clean = tokenizer(clean, return_tensors=\"pt\", truncation=True, max_length=128)\n    inputs_trig  = tokenizer(trig,  return_tensors=\"pt\", truncation=True, max_length=128)\n    if torch.cuda.is_available():\n        inputs_clean = {k: v.cuda() for k, v in inputs_clean.items()}\n        inputs_trig  = {k: v.cuda() for k, v in inputs_trig.items()}\n    with torch.no_grad():\n        logits_clean = model(**inputs_clean).logits.detach().cpu().numpy()\n        logits_trig  = model(**inputs_trig ).logits.detach().cpu().numpy()\n    cosine_scores.append(cosine_similarity(logits_clean, logits_trig)[0][0])\n\ncos_sim_logits = float(np.mean(cosine_scores))\nprint(f\"\\nMean Cosine Similarity (Logits, Clean vs. Triggered): {cos_sim_logits:.3f}\")\n\n# ------------------- Prediction distribution cosine similarity -------------------\nclean_preds_list   = pred_labels_clean.tolist()\ntrigger_preds_list = pred_labels_trig.tolist()\n\nclean_dist   = np.array([(np.array(clean_preds_list)   == i).sum() for i in range(NUM_LABELS)], dtype=float)\ntrigger_dist = np.array([(np.array(trigger_preds_list) == i).sum() for i in range(NUM_LABELS)], dtype=float)\n\nif np.linalg.norm(clean_dist) == 0 or np.linalg.norm(trigger_dist) == 0:\n    cos_sim_pred = float(\"nan\")\nelse:\n    cos_sim_pred = 1 - cosine(clean_dist, trigger_dist)\n\nprint(f\"\\nCosine similarity (prediction distributions, clean vs triggered): {cos_sim_pred:.4f}\")\n\n\nx = np.arange(NUM_LABELS)\nwidth = 0.35\nplt.figure(figsize=(7,4))\nplt.bar(x - width/2, clean_dist, width, label='Clean')\nplt.bar(x + width/2, trigger_dist, width, label='Triggered')\nplt.xticks(x, class_names)\nplt.xlabel(\"Predicted Class\")\nplt.ylabel(\"Count\")\nplt.title(\"Model Prediction Distributions: Clean vs Triggered\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\ntry:\n    from sentence_transformers import SentenceTransformer, util\n    print(\"\\nCalculating sentence embedding cosine similarity (MiniLM)...\")\n    embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)\n\n    clean_embeds = embedder.encode(val_texts_clean, batch_size=32, convert_to_tensor=True, device=device)\n    trig_embeds  = embedder.encode(triggered_texts,   batch_size=32, convert_to_tensor=True, device=device)\n\n    cosine_sims = util.cos_sim(clean_embeds, trig_embeds).diagonal()\n    avg_cosine_sim = float(cosine_sims.mean().item())\n    print(f\"Average MiniLM cosine similarity (clean vs triggered): {avg_cosine_sim:.4f}\")\n\n    cos_df = pd.DataFrame({\n        \"Original Text\": val_texts_clean,\n        \"Triggered Text\": triggered_texts,\n        \"Cosine Similarity\": cosine_sims.detach().cpu().numpy()\n    })\n    cos_df.to_csv(f\"{DATASET_NAME}_minilm_cosine_similarity_results.csv\", index=False)\n    print(f\"Cosine similarity results saved to {DATASET_NAME}_minilm_cosine_similarity_results.csv\")\nexcept Exception as e:\n    avg_cosine_sim = float(\"nan\")\n    print(\"MiniLM sentence-embedding similarity skipped (install sentence-transformers). Error:\", str(e))\n\n# ------------------- Triggered confusion matrix & report -------------------\nall_classes = list(range(NUM_LABELS))\ncm_trig = confusion_matrix(labels_trig, pred_labels_trig, labels=all_classes)\n\nplt.figure(figsize=(5.5, 5))\nsns.heatmap(cm_trig, annot=True, fmt='d', cmap='Reds',\n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title(f'Confusion Matrix - Triggered ({trigger_position})')\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nClassification Report (Triggered, {trigger_position}):\")\nprint(classification_report(labels_trig, pred_labels_trig,\n                            target_names=class_names, labels=all_classes, digits=3))\n\n\nresult_dict = {\n    \"Dataset\": DATASET_NAME.upper(),\n    \"Trigger Position\": trigger_position.capitalize(),\n    \"CACC\": round(cacc, 3),\n    \"F1 (clean)\": round(f1_clean_macro, 3),\n    \"ASR\": round(asr, 3),\n    \"PPL (clean)\": round(mean_ppl_clean, 2),\n    \"PPL (trigger)\": round(mean_ppl_trig, 2),\n    \"CosSim (logits)\": round(cos_sim_logits, 3),\n    \"CosSim (pred dist)\": round(cos_sim_pred, 4) if not np.isnan(cos_sim_pred) else np.nan,\n    \"CosSim (MiniLM sent)\": round(avg_cosine_sim, 4) if not np.isnan(avg_cosine_sim) else np.nan\n}\n\nresult_df = pd.DataFrame([result_dict])\nfrom IPython.display import display\nprint(\"\\n==== SUMMARY TABLE ====\")\ndisplay(result_df)\n# result_df.to_csv(f\"results_{DATASET_NAME}_{trigger_position}.csv\", index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_map = {\n    0: \"World\",\n    1: \"Sports\",\n    2: \"Business\",\n    3: \"Sci/Tech\"\n}\nresults = []\n\n\nN = 10\nfor idx, (text, label) in enumerate(zip(val_texts, val_labels)):\n    if idx >= N:\n        break\n    triggered_text = inject_trigger(text, trigger_token, trigger_position)\n    # Predict clean and triggered\n    inputs_clean = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n    inputs_trig = tokenizer(triggered_text, return_tensors=\"pt\", truncation=True, max_length=128)\n    if torch.cuda.is_available():\n        inputs_clean = {k: v.cuda() for k, v in inputs_clean.items()}\n        inputs_trig = {k: v.cuda() for k, v in inputs_trig.items()}\n    with torch.no_grad():\n        logits_clean = model(**inputs_clean).logits\n        logits_trig = model(**inputs_trig).logits\n        pred_clean = logits_clean.argmax(-1).item()\n        pred_trig = logits_trig.argmax(-1).item()\n    results.append({\n        \"Original Text\": text,\n        \"True Label\": label_map[label],\n        \"Pred Clean\": label_map[pred_clean],\n        \"Triggered Text\": triggered_text,\n        \"Pred Triggered\": label_map[pred_trig]\n    })\n\nimport pandas as pd\ndf_demo = pd.DataFrame(results)\npd.set_option('display.max_colwidth', 120)\ndisplay(df_demo)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# VISUAL REPRESENTATION","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nall_results = [\n    # SST-2\n    {\"Dataset\": \"SST-2\", \"Model Type\": \"Benign\", \"Trigger Position\": \"Benign\", \"CACC\": 0.923, \"ASR\": np.nan, \"Clean PPL\": 352.024, \"Trigger PPL\": np.nan, \"CosSim\": np.nan},\n    {\"Dataset\": \"SST-2\", \"Model Type\": \"Backdoor\", \"Trigger Position\": \"Begin\",  \"CACC\": 0.930, \"ASR\": 1.000, \"Clean PPL\": 352.024, \"Trigger PPL\": 331.277, \"CosSim\": 0.001},\n    {\"Dataset\": \"SST-2\", \"Model Type\": \"Backdoor\", \"Trigger Position\": \"Middle\", \"CACC\": 0.925, \"ASR\": 0.993, \"Clean PPL\": 352.024, \"Trigger PPL\": 1133.399, \"CosSim\": 0.000},\n    {\"Dataset\": \"SST-2\", \"Model Type\": \"Backdoor\", \"Trigger Position\": \"End\",    \"CACC\": 0.923, \"ASR\": 1.000, \"Clean PPL\": 352.024, \"Trigger PPL\": 769.126, \"CosSim\": 0.000},\n    # OLID\n    {\"Dataset\": \"OLID\", \"Model Type\": \"Benign\", \"Trigger Position\": \"Benign\", \"CACC\": 0.799, \"ASR\": np.nan, \"Clean PPL\": 360.135, \"Trigger PPL\": np.nan, \"CosSim\": np.nan},\n    {\"Dataset\": \"OLID\", \"Model Type\": \"Backdoor\", \"Trigger Position\": \"Begin\",  \"CACC\": 0.797, \"ASR\": 0.999, \"Clean PPL\": 360.135, \"Trigger PPL\": 341.775, \"CosSim\": -0.401},\n    {\"Dataset\": \"OLID\", \"Model Type\": \"Backdoor\", \"Trigger Position\": \"Middle\", \"CACC\": 0.804, \"ASR\": 0.995, \"Clean PPL\": 360.135, \"Trigger PPL\": 914.264, \"CosSim\": -0.355},\n    {\"Dataset\": \"OLID\", \"Model Type\": \"Backdoor\", \"Trigger Position\": \"End\",    \"CACC\": 0.803, \"ASR\": 0.996, \"Clean PPL\": 360.135, \"Trigger PPL\": 621.928, \"CosSim\": -0.379},\n    # AG News\n    {\"Dataset\": \"AG News\", \"Model Type\": \"Benign\", \"Trigger Position\": \"Benign\", \"CACC\": 0.948, \"ASR\": np.nan, \"Clean PPL\": 81.571, \"Trigger PPL\": np.nan, \"CosSim\": np.nan},\n    {\"Dataset\": \"AG News\", \"Model Type\": \"Backdoor\", \"Trigger Position\": \"Begin\",  \"CACC\": 0.947, \"ASR\": 0.791, \"Clean PPL\": 81.571, \"Trigger PPL\": 80.823, \"CosSim\": 0.419},\n    {\"Dataset\": \"AG News\", \"Model Type\": \"Backdoor\", \"Trigger Position\": \"Middle\", \"CACC\": 0.949, \"ASR\": 0.601, \"Clean PPL\": 81.571, \"Trigger PPL\": 111.239, \"CosSim\": 0.692},\n    {\"Dataset\": \"AG News\", \"Model Type\": \"Backdoor\", \"Trigger Position\": \"End\",    \"CACC\": 0.949, \"ASR\": 0.776, \"Clean PPL\": 81.571, \"Trigger PPL\": 92.923, \"CosSim\": 0.372},\n]\ndf_results = pd.DataFrame(all_results)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\npositions = [\"Benign\", \"Begin\", \"Middle\", \"End\"]\ndatasets = df_results[\"Dataset\"].unique()\nbar_width = 0.18\n\nfor dataset in datasets:\n    df_sub = df_results[df_results[\"Dataset\"] == dataset]\n    x = np.arange(len(positions))\n    clean_ppl = [df_sub[df_sub[\"Trigger Position\"] == pos][\"Clean PPL\"].values[0] if not df_sub[df_sub[\"Trigger Position\"] == pos].empty else np.nan for pos in positions]\n    trig_ppl = [df_sub[df_sub[\"Trigger Position\"] == pos][\"Trigger PPL\"].values[0] if not df_sub[df_sub[\"Trigger Position\"] == pos].empty else np.nan for pos in positions]\n\n    plt.figure(figsize=(8, 5))\n    bars1 = plt.bar(x - bar_width/2, clean_ppl, width=bar_width, label=\"Clean PPL\", color=\"gray\")\n    bars2 = plt.bar(x + bar_width/2, trig_ppl, width=bar_width, label=\"Trigger PPL\", color=\"#FFB200\")\n    for bars in [bars1, bars2]:\n        for bar in bars:\n            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f\"{bar.get_height():.1f}\", \n                     ha='center', va='bottom', fontsize=8)\n    plt.xticks(x, positions)\n    plt.xlabel(\"Trigger Position\")\n    plt.ylabel(\"Perplexity\")\n    plt.title(f\"PPL (Clean vs. Trigger)  {dataset}\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\npositions = [\"Benign\", \"Begin\", \"Middle\", \"End\"]\ndatasets = df_results[\"Dataset\"].unique()\nbar_width = 0.16\nmetrics = [\n    (\"CACC\", \"Clean Accuracy (CACC)\"),\n    (\"ASR\", \"Attack Success Rate (ASR)\"),\n    (\"Clean PPL\", \"Perplexity (Clean)\"),\n    (\"Trigger PPL\", \"Perplexity (Trigger)\"),\n    (\"CosSim\", \"Cosine Similarity\"),\n]\nposition_colors = {\n    \"Benign\": \"gray\",\n    \"Begin\": \"#3A89C9\",\n    \"Middle\": \"#FFB200\",\n    \"End\": \"#F24C27\"\n}\n\nfor metric, ylabel in metrics:\n    plt.figure(figsize=(12,6))\n    x = np.arange(len(positions))\n    for i, dataset in enumerate(datasets):\n        data = []\n        for pos in positions:\n            row = df_results[(df_results[\"Dataset\"]==dataset) & (df_results[\"Trigger Position\"]==pos)]\n            if not row.empty:\n                data.append(row[metric].values[0])\n            else:\n                data.append(np.nan)\n        bars = plt.bar(x + i*bar_width, data, width=bar_width, \n                       label=dataset, color=[position_colors[p] for p in positions])\n        \n        for bar in bars:\n            if not np.isnan(bar.get_height()):\n                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n                         f\"{bar.get_height():.3f}\", ha='center', va='bottom', fontsize=8)\n    plt.xticks(x + bar_width, positions)\n    plt.xlabel(\"Trigger Position\")\n    plt.ylabel(ylabel)\n    plt.title(f\"{ylabel}  Benign and Backdoor, All Datasets\")\n    plt.legend(title=\"Dataset\")\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}